





<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
  <link rel="dns-prefetch" href="https://assets-cdn.github.com">
  <link rel="dns-prefetch" href="https://avatars0.githubusercontent.com">
  <link rel="dns-prefetch" href="https://avatars1.githubusercontent.com">
  <link rel="dns-prefetch" href="https://avatars2.githubusercontent.com">
  <link rel="dns-prefetch" href="https://avatars3.githubusercontent.com">
  <link rel="dns-prefetch" href="https://github-cloud.s3.amazonaws.com">
  <link rel="dns-prefetch" href="https://user-images.githubusercontent.com/">



  <link crossorigin="anonymous" media="all" integrity="sha512-AE1SjlpGWrlEnSwNeIPt4xzHKf9cqRgDSKEZilZfa2Eo6yF0O/JHA+sn7rwD8Q0SQZ7mxR6UthJmqpjc7eRufQ==" rel="stylesheet" href="https://assets-cdn.github.com/assets/frameworks-35bdc21c9cfe5499e25ab7ce9d31a2cc.css" />
  <link crossorigin="anonymous" media="all" integrity="sha512-gAR5eO5DRc48LzTBGYVK9Q8Eq3LZ2T3dKUuLWVfkfdWPnJyhPaY/ivsh67Fy8c2dQPso0h8lBVngDlb/du1H7w==" rel="stylesheet" href="https://assets-cdn.github.com/assets/github-53c9bcdc66bd65746c42e29457a4e2ab.css" />
  
  
  
  

  <meta name="viewport" content="width=device-width">
  
  <title>jbhuang0604/awesome-computer-vision: A curated list of awesome computer vision resources</title>
    <meta name="description" content="GitHub is where people build software. More than 27 million people use GitHub to discover, fork, and contribute to over 80 million projects.">
  <link rel="search" type="application/opensearchdescription+xml" href="/opensearch.xml" title="GitHub">
  <link rel="fluid-icon" href="https://github.com/fluidicon.png" title="GitHub">
  <meta property="fb:app_id" content="1401488693436528">

    
    <meta property="og:image" content="https://avatars0.githubusercontent.com/u/987204?s=400&amp;v=4" /><meta property="og:site_name" content="GitHub" /><meta property="og:type" content="object" /><meta property="og:title" content="jbhuang0604/awesome-computer-vision" /><meta property="og:url" content="https://github.com/jbhuang0604/awesome-computer-vision" /><meta property="og:description" content="awesome-computer-vision - A curated list of awesome computer vision resources" />

  <link rel="assets" href="https://assets-cdn.github.com/">
  <link rel="web-socket" href="wss://live.github.com/_sockets/VjI6MjY3MzgwMDc4OmNkNWEzYjg1MjgxYzg2NmU3NjA0NmEyNmMyMzgzMTA4ZjEwZjkwOTFkMzM2MzA3MGVkZmUwMjJiYzRhNjk0ZTY=--1de580901a4f8a047dc621bfe0a9850cd10f11f2">
  <meta name="pjax-timeout" content="1000">
  <link rel="sudo-modal" href="/sessions/sudo_modal">
  <meta name="request-id" content="19B6:1682:189E9CC:2EF5AEE:5AF5C0E2" data-pjax-transient>


  

  <meta name="selected-link" value="repo_source" data-pjax-transient>

    <meta name="google-site-verification" content="KT5gs8h0wvaagLKAVWq8bbeNwnZZK1r1XQysX3xurLU">
  <meta name="google-site-verification" content="ZzhVyEFwb7w3e0-uOTltm8Jsck2F5StVihD0exw2fsA">
  <meta name="google-site-verification" content="GXs5KoUUkNCoaAZn7wPN-t01Pywp9M3sEjnt_3_ZWPc">
    <meta name="google-analytics" content="UA-3769691-2">

<meta name="octolytics-host" content="collector.githubapp.com" /><meta name="octolytics-app-id" content="github" /><meta name="octolytics-event-url" content="https://collector.githubapp.com/github-external/browser_event" /><meta name="octolytics-dimension-request_id" content="19B6:1682:189E9CC:2EF5AEE:5AF5C0E2" /><meta name="octolytics-dimension-region_edge" content="iad" /><meta name="octolytics-dimension-region_render" content="iad" /><meta name="octolytics-actor-id" content="11485092" /><meta name="octolytics-actor-login" content="data-raj" /><meta name="octolytics-actor-hash" content="6453d983f598874927eb4747ca9a345041bd40255081a6ff297ff3b2368794fc" />
<meta name="analytics-location" content="/&lt;user-name&gt;/&lt;repo-name&gt;" data-pjax-transient="true" />




  <meta class="js-ga-set" name="dimension1" content="Logged In">


  

      <meta name="hostname" content="github.com">
    <meta name="user-login" content="data-raj">

      <meta name="expected-hostname" content="github.com">
    <meta name="js-proxy-site-detection-payload" content="OTFiODk0MzIwMmUwZjU4MGFkNmY2YjdlMjllMmRkZmY5MDljNTFmNjEyMmQzOTU1OTRkZDM0ZWExY2U0ZGZhZHx7InJlbW90ZV9hZGRyZXNzIjoiMTgwLjE1MS4xNjMuMTAzIiwicmVxdWVzdF9pZCI6IjE5QjY6MTY4MjoxODlFOUNDOjJFRjVBRUU6NUFGNUMwRTIiLCJ0aW1lc3RhbXAiOjE1MjYwNTUxMzksImhvc3QiOiJnaXRodWIuY29tIn0=">

    <meta name="enabled-features" content="UNIVERSE_BANNER,FREE_TRIALS,MARKETPLACE_INSIGHTS,MARKETPLACE_SELF_SERVE,MARKETPLACE_FREE_APPS,MARKETPLACE_INSIGHTS_CONVERSION_PERCENTAGES">

  <meta name="html-safe-nonce" content="3fe38877ce13d52ad8ded42f3e689565cb79249f">

  <meta http-equiv="x-pjax-version" content="43b3a2b3388114771b5989189f5c7723">
  

      <link href="https://github.com/jbhuang0604/awesome-computer-vision/commits/master.atom" rel="alternate" title="Recent Commits to awesome-computer-vision:master" type="application/atom+xml">

  <meta name="description" content="awesome-computer-vision - A curated list of awesome computer vision resources">
  <meta name="go-import" content="github.com/jbhuang0604/awesome-computer-vision git https://github.com/jbhuang0604/awesome-computer-vision.git">

  <meta name="octolytics-dimension-user_id" content="987204" /><meta name="octolytics-dimension-user_login" content="jbhuang0604" /><meta name="octolytics-dimension-repository_id" content="29357796" /><meta name="octolytics-dimension-repository_nwo" content="jbhuang0604/awesome-computer-vision" /><meta name="octolytics-dimension-repository_public" content="true" /><meta name="octolytics-dimension-repository_is_fork" content="false" /><meta name="octolytics-dimension-repository_network_root_id" content="29357796" /><meta name="octolytics-dimension-repository_network_root_nwo" content="jbhuang0604/awesome-computer-vision" /><meta name="octolytics-dimension-repository_explore_github_marketplace_ci_cta_shown" content="false" />


    <link rel="canonical" href="https://github.com/jbhuang0604/awesome-computer-vision" data-pjax-transient>


  <meta name="browser-stats-url" content="https://api.github.com/_private/browser/stats">

  <meta name="browser-errors-url" content="https://api.github.com/_private/browser/errors">

  <link rel="mask-icon" href="https://assets-cdn.github.com/pinned-octocat.svg" color="#000000">
  <link rel="icon" type="image/x-icon" class="js-site-favicon" href="https://assets-cdn.github.com/favicon.ico">

<meta name="theme-color" content="#1e2327">


  <meta name="u2f-support" content="true">

<link rel="manifest" href="/manifest.json" crossOrigin="use-credentials">

  </head>

  <body class="logged-in env-production">
    

  <div class="position-relative js-header-wrapper ">
    <a href="#start-of-content" tabindex="1" class="p-3 bg-blue text-white show-on-focus js-skip-to-content">Skip to content</a>
    <div id="js-pjax-loader-bar" class="pjax-loader-bar"><div class="progress"></div></div>

    
    
    



        
<header class="Header  f5" role="banner">
  <div class="d-flex flex-justify-between px-3 container-lg">
    <div class="d-flex flex-justify-between ">
      <div class="">
        <a class="header-logo-invertocat" href="https://github.com/" data-hotkey="g d" aria-label="Homepage" data-ga-click="Header, go to dashboard, icon:logo">
  <svg height="32" class="octicon octicon-mark-github" viewBox="0 0 16 16" version="1.1" width="32" aria-hidden="true"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"/></svg>
</a>

      </div>

    </div>

    <div class="HeaderMenu d-flex flex-justify-between flex-auto">
      <div class="d-flex">
            <div class="">
              <div class="header-search scoped-search site-scoped-search js-site-search" role="search">
  <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="js-site-search-form" data-scope-type="Repository" data-scope-id="29357796" data-scoped-search-url="/jbhuang0604/awesome-computer-vision/search" data-unscoped-search-url="/search" action="/jbhuang0604/awesome-computer-vision/search" accept-charset="UTF-8" method="get"><input name="utf8" type="hidden" value="&#x2713;" />
    <label class="form-control header-search-wrapper  js-chromeless-input-container">
          <a class="header-search-scope no-underline" href="/jbhuang0604/awesome-computer-vision">This repository</a>
      <input type="text"
        class="form-control header-search-input  js-site-search-focus js-site-search-field is-clearable"
        data-hotkey="s,/"
        name="q"
        value=""
        placeholder="Search"
        aria-label="Search this repository"
        data-unscoped-placeholder="Search GitHub"
        data-scoped-placeholder="Search"
        autocapitalize="off"
        >
        <input type="hidden" class="js-site-search-type-field" name="type" >
    </label>
</form></div>

            </div>

          <ul class="d-flex pl-2 flex-items-center text-bold list-style-none" role="navigation">
            <li>
              <a class="js-selected-navigation-item HeaderNavlink px-2" data-hotkey="g p" data-ga-click="Header, click, Nav menu - item:pulls context:user" aria-label="Pull requests you created" data-selected-links="/pulls /pulls/assigned /pulls/mentioned /pulls" href="/pulls">
                Pull requests
</a>            </li>
            <li>
              <a class="js-selected-navigation-item HeaderNavlink px-2" data-hotkey="g i" data-ga-click="Header, click, Nav menu - item:issues context:user" aria-label="Issues you created" data-selected-links="/issues /issues/assigned /issues/mentioned /issues" href="/issues">
                Issues
</a>            </li>
                <li>
                  <a class="js-selected-navigation-item HeaderNavlink px-2" data-ga-click="Header, click, Nav menu - item:marketplace context:user" data-octo-click="marketplace_click" data-octo-dimensions="location:nav_bar, group:" data-selected-links=" /marketplace" href="/marketplace">
                    Marketplace
</a>                </li>
            <li>
              <a class="js-selected-navigation-item HeaderNavlink px-2" data-ga-click="Header, click, Nav menu - item:explore" data-selected-links="/explore /trending /trending/developers /integrations /integrations/feature/code /integrations/feature/collaborate /integrations/feature/ship showcases showcases_search showcases_landing /explore" href="/explore">
                Explore
</a>            </li>
          </ul>
      </div>

      <div class="d-flex">
        
<ul class="user-nav d-flex flex-items-center list-style-none" id="user-links">
  <li class="dropdown js-menu-container">
    <span class="d-inline-block  px-2">
      
    <a aria-label="You have no unread notifications" class="notification-indicator tooltipped tooltipped-s  js-socket-channel js-notification-indicator" data-hotkey="g n" data-ga-click="Header, go to notifications, icon:read" data-channel="notification-changed:11485092" href="/notifications">
        <span class="mail-status "></span>
        <svg class="octicon octicon-bell" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M13.99 11.991v1H0v-1l.73-.58c.769-.769.809-2.547 1.189-4.416.77-3.767 4.077-4.996 4.077-4.996 0-.55.45-1 .999-1 .55 0 1 .45 1 1 0 0 3.387 1.229 4.156 4.996.38 1.879.42 3.657 1.19 4.417l.659.58h-.01zM6.995 15.99c1.11 0 1.999-.89 1.999-1.999H4.996c0 1.11.89 1.999 1.999 1.999z"/></svg>
</a>
    </span>
  </li>

  <li class="dropdown js-menu-container">
    <details class="dropdown-details details-reset js-dropdown-details d-flex px-2 flex-items-center">
      <summary class="HeaderNavlink"
         aria-label="Create new…"
         data-ga-click="Header, create new, icon:add">
        <svg class="octicon octicon-plus float-left mr-1 mt-1" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M12 9H7v5H5V9H0V7h5V2h2v5h5v2z"/></svg>
        <span class="dropdown-caret mt-1"></span>
      </summary>

      <ul class="dropdown-menu dropdown-menu-sw">
        
<a class="dropdown-item" href="/new" data-ga-click="Header, create new repository">
  New repository
</a>

  <a class="dropdown-item" href="/new/import" data-ga-click="Header, import a repository">
    Import repository
  </a>

<a class="dropdown-item" href="https://gist.github.com/" data-ga-click="Header, create new gist">
  New gist
</a>

  <a class="dropdown-item" href="/organizations/new" data-ga-click="Header, create new organization">
    New organization
  </a>



  <div class="dropdown-divider"></div>
  <div class="dropdown-header">
    <span title="jbhuang0604/awesome-computer-vision">This repository</span>
  </div>
    <a class="dropdown-item" href="/jbhuang0604/awesome-computer-vision/issues/new" data-ga-click="Header, create new issue">
      New issue
    </a>

      </ul>
    </details>
  </li>

  <li class="dropdown js-menu-container">

    <details class="dropdown-details details-reset js-dropdown-details d-flex pl-2 flex-items-center">
      <summary class="HeaderNavlink name mt-1"
        aria-label="View profile and more"
        data-ga-click="Header, show menu, icon:avatar">
        <img alt="@data-raj" class="avatar float-left mr-1" src="https://avatars1.githubusercontent.com/u/11485092?s=40&amp;v=4" height="20" width="20">
        <span class="dropdown-caret"></span>
      </summary>

      <ul class="dropdown-menu dropdown-menu-sw">
        <li class="dropdown-header header-nav-current-user css-truncate">
          Signed in as <strong class="css-truncate-target">data-raj</strong>
        </li>

        <li class="dropdown-divider"></li>

        <li><a class="dropdown-item" href="/data-raj" data-ga-click="Header, go to profile, text:your profile">
          Your profile
        </a></li>
        <li><a class="dropdown-item" href="/data-raj?tab=stars" data-ga-click="Header, go to starred repos, text:your stars">
          Your stars
        </a></li>
          <li><a class="dropdown-item" href="https://gist.github.com/" data-ga-click="Header, your gists, text:your gists">Your gists</a></li>

        <li class="dropdown-divider"></li>

        <li><a class="dropdown-item" href="https://help.github.com" data-ga-click="Header, go to help, text:help">
          Help
        </a></li>

        <li><a class="dropdown-item" href="/settings/profile" data-ga-click="Header, go to settings, icon:settings">
          Settings
        </a></li>

        <li><!-- '"` --><!-- </textarea></xmp> --></option></form><form class="logout-form" action="/logout" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="8hTJ0JGQIvWvinn55BDyju1p698VrRHn855lbda1Chys1xbPLDFSj0sRiSl+CPLSJ0DJJjuSpkPszBwpRnn6hg==" />
          <button type="submit" class="dropdown-item dropdown-signout" data-ga-click="Header, sign out, icon:logout">
            Sign out
          </button>
        </form></li>
      </ul>
    </details>
  </li>
</ul>



        <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="sr-only right-0" action="/logout" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="vIlJ9ixSapYv+37njSmS1i5qlCvf+5VGvyYmkA1qi13iSpbpkfMa7MtgjjcXMZKK5EO20vHEIuKgdF/UnaZ7xw==" />
          <button type="submit" class="dropdown-item dropdown-signout" data-ga-click="Header, sign out, icon:logout">
            Sign out
          </button>
</form>      </div>
    </div>
  </div>
</header>

      

  </div>

  <div id="start-of-content" class="show-on-focus"></div>

    <div id="js-flash-container">
</div>



  <div role="main" class="application-main ">
        <div itemscope itemtype="http://schema.org/SoftwareSourceCode" class="">
    <div id="js-repo-pjax-container" data-pjax-container >
      





  <div class="pagehead repohead instapaper_ignore readability-menu experiment-repo-nav  ">
    <div class="repohead-details-container clearfix container">

      <ul class="pagehead-actions">
  <li>
        <!-- '"` --><!-- </textarea></xmp> --></option></form><form data-autosubmit="true" data-remote="true" class="js-social-container" action="/notifications/subscribe" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="pu6ShouhRAgWEgrJXZAJk3n3piAKwIzYj+dZzGXNDp5jY2XS6sYXlfR1VFr/dExZmTZzJ9EEYGNVH7dipEj9qQ==" />      <input type="hidden" name="repository_id" id="repository_id" value="29357796" class="form-control" />

        <div class="select-menu js-menu-container js-select-menu">
          <a href="/jbhuang0604/awesome-computer-vision/subscription"
            class="btn btn-sm btn-with-count select-menu-button js-menu-target"
            role="button"
            aria-haspopup="true"
            aria-expanded="false"
            aria-label="Toggle repository notifications menu"
            data-ga-click="Repository, click Watch settings, action:files#disambiguate">
            <span class="js-select-button">
                <svg class="octicon octicon-eye" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.06 2C3 2 0 8 0 8s3 6 8.06 6C13 14 16 8 16 8s-3-6-7.94-6zM8 12c-2.2 0-4-1.78-4-4 0-2.2 1.8-4 4-4 2.22 0 4 1.8 4 4 0 2.22-1.78 4-4 4zm2-4c0 1.11-.89 2-2 2-1.11 0-2-.89-2-2 0-1.11.89-2 2-2 1.11 0 2 .89 2 2z"/></svg>
                Watch
            </span>
          </a>
          <a class="social-count js-social-count"
            href="/jbhuang0604/awesome-computer-vision/watchers"
            aria-label="825 users are watching this repository">
            825
          </a>

        <div class="select-menu-modal-holder">
          <div class="select-menu-modal subscription-menu-modal js-menu-content">
            <div class="select-menu-header js-navigation-enable" tabindex="-1">
              <svg class="octicon octicon-x js-menu-close" role="img" aria-label="Close" viewBox="0 0 12 16" version="1.1" width="12" height="16"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48L7.48 8z"/></svg>
              <span class="select-menu-title">Notifications</span>
            </div>

              <div class="select-menu-list js-navigation-container" role="menu">

                <div class="select-menu-item js-navigation-item selected" role="menuitem" tabindex="0">
                  <svg class="octicon octicon-check select-menu-item-icon" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5L12 5z"/></svg>
                  <div class="select-menu-item-text">
                    <input type="radio" name="do" id="do_included" value="included" checked="checked" />
                    <span class="select-menu-item-heading">Not watching</span>
                    <span class="description">Be notified when participating or @mentioned.</span>
                    <span class="js-select-button-text hidden-select-button-text">
                      <svg class="octicon octicon-eye" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.06 2C3 2 0 8 0 8s3 6 8.06 6C13 14 16 8 16 8s-3-6-7.94-6zM8 12c-2.2 0-4-1.78-4-4 0-2.2 1.8-4 4-4 2.22 0 4 1.8 4 4 0 2.22-1.78 4-4 4zm2-4c0 1.11-.89 2-2 2-1.11 0-2-.89-2-2 0-1.11.89-2 2-2 1.11 0 2 .89 2 2z"/></svg>
                      Watch
                    </span>
                  </div>
                </div>

                <div class="select-menu-item js-navigation-item " role="menuitem" tabindex="0">
                  <svg class="octicon octicon-check select-menu-item-icon" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5L12 5z"/></svg>
                  <div class="select-menu-item-text">
                    <input type="radio" name="do" id="do_subscribed" value="subscribed" />
                    <span class="select-menu-item-heading">Watching</span>
                    <span class="description">Be notified of all conversations.</span>
                    <span class="js-select-button-text hidden-select-button-text">
                      <svg class="octicon octicon-eye" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.06 2C3 2 0 8 0 8s3 6 8.06 6C13 14 16 8 16 8s-3-6-7.94-6zM8 12c-2.2 0-4-1.78-4-4 0-2.2 1.8-4 4-4 2.22 0 4 1.8 4 4 0 2.22-1.78 4-4 4zm2-4c0 1.11-.89 2-2 2-1.11 0-2-.89-2-2 0-1.11.89-2 2-2 1.11 0 2 .89 2 2z"/></svg>
                        Unwatch
                    </span>
                  </div>
                </div>

                <div class="select-menu-item js-navigation-item " role="menuitem" tabindex="0">
                  <svg class="octicon octicon-check select-menu-item-icon" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5L12 5z"/></svg>
                  <div class="select-menu-item-text">
                    <input type="radio" name="do" id="do_ignore" value="ignore" />
                    <span class="select-menu-item-heading">Ignoring</span>
                    <span class="description">Never be notified.</span>
                    <span class="js-select-button-text hidden-select-button-text">
                      <svg class="octicon octicon-mute" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 2.81v10.38c0 .67-.81 1-1.28.53L3 10H1c-.55 0-1-.45-1-1V7c0-.55.45-1 1-1h2l3.72-3.72C7.19 1.81 8 2.14 8 2.81zm7.53 3.22l-1.06-1.06-1.97 1.97-1.97-1.97-1.06 1.06L11.44 8 9.47 9.97l1.06 1.06 1.97-1.97 1.97 1.97 1.06-1.06L13.56 8l1.97-1.97z"/></svg>
                        Stop ignoring
                    </span>
                  </div>
                </div>

              </div>

            </div>
          </div>
        </div>
</form>
  </li>

  <li>
    
  <div class="js-toggler-container js-social-container starring-container ">
    <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="starred js-social-form" action="/jbhuang0604/awesome-computer-vision/unstar" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="qjEXto0UXO8Q38fyEDQV8Xvqo90Cchfu0BRYoi66tOjJNVzLKkdVDcE3pTZAH3itLeIy630/6k51Vo+bjTeGPA==" />
      <input type="hidden" name="context" value="repository"></input>
      <button
        type="submit"
        class="btn btn-sm btn-with-count js-toggler-target"
        aria-label="Unstar this repository" title="Unstar jbhuang0604/awesome-computer-vision"
        data-ga-click="Repository, click unstar button, action:files#disambiguate; text:Unstar">
        <svg class="octicon octicon-star" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M14 6l-4.9-.64L7 1 4.9 5.36 0 6l3.6 3.26L2.67 14 7 11.67 11.33 14l-.93-4.74L14 6z"/></svg>
        Unstar
      </button>
        <a class="social-count js-social-count" href="/jbhuang0604/awesome-computer-vision/stargazers"
           aria-label="7308 users starred this repository">
          7,308
        </a>
</form>
    <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="unstarred js-social-form" action="/jbhuang0604/awesome-computer-vision/star" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="CYl3tHbv4ES8svjdlUbGzpjtuTlLszjgdSpd6o083kgteuR/NtjxkhsOR6EW2X3Mzoy+wG8xH0KP5UkJZd84kg==" />
      <input type="hidden" name="context" value="repository"></input>
      <button
        type="submit"
        class="btn btn-sm btn-with-count js-toggler-target"
        aria-label="Star this repository" title="Star jbhuang0604/awesome-computer-vision"
        data-ga-click="Repository, click star button, action:files#disambiguate; text:Star">
        <svg class="octicon octicon-star" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M14 6l-4.9-.64L7 1 4.9 5.36 0 6l3.6 3.26L2.67 14 7 11.67 11.33 14l-.93-4.74L14 6z"/></svg>
        Star
      </button>
        <a class="social-count js-social-count" href="/jbhuang0604/awesome-computer-vision/stargazers"
           aria-label="7308 users starred this repository">
          7,308
        </a>
</form>  </div>

  </li>

  <li>
          <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="btn-with-count" action="/jbhuang0604/awesome-computer-vision/fork" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="+V8GGhHxKwWre3DifI4eqjTP/4WeBq6OmYZl8NpNuW/CnQU/YVCMQe3veZu5DUJNep4kmLHekLnC9kfqTC29yw==" />
            <button
                type="submit"
                class="btn btn-sm btn-with-count"
                data-ga-click="Repository, show fork modal, action:files#disambiguate; text:Fork"
                title="Fork your own copy of jbhuang0604/awesome-computer-vision to your account"
                aria-label="Fork your own copy of jbhuang0604/awesome-computer-vision to your account">
              <svg class="octicon octicon-repo-forked" viewBox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1a1.993 1.993 0 0 0-1 3.72V6L5 8 3 6V4.72A1.993 1.993 0 0 0 2 1a1.993 1.993 0 0 0-1 3.72V6.5l3 3v1.78A1.993 1.993 0 0 0 5 15a1.993 1.993 0 0 0 1-3.72V9.5l3-3V4.72A1.993 1.993 0 0 0 8 1zM2 4.2C1.34 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zm3 10c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zm3-10c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z"/></svg>
              Fork
            </button>
</form>
    <a href="/jbhuang0604/awesome-computer-vision/network" class="social-count"
       aria-label="1927 users forked this repository">
      1,927
    </a>
  </li>
</ul>

      <h1 class="public ">
  <svg class="octicon octicon-repo" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z"/></svg>
  <span class="author" itemprop="author"><a class="url fn" rel="author" href="/jbhuang0604">jbhuang0604</a></span><!--
--><span class="path-divider">/</span><!--
--><strong itemprop="name"><a data-pjax="#js-repo-pjax-container" href="/jbhuang0604/awesome-computer-vision">awesome-computer-vision</a></strong>

</h1>

    </div>
    
<nav class="reponav js-repo-nav js-sidenav-container-pjax container"
     itemscope
     itemtype="http://schema.org/BreadcrumbList"
     role="navigation"
     data-pjax="#js-repo-pjax-container">

  <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
    <a class="js-selected-navigation-item selected reponav-item" itemprop="url" data-hotkey="g c" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages /jbhuang0604/awesome-computer-vision" href="/jbhuang0604/awesome-computer-vision">
      <svg class="octicon octicon-code" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M9.5 3L8 4.5 11.5 8 8 11.5 9.5 13 14 8 9.5 3zm-5 0L0 8l4.5 5L6 11.5 2.5 8 6 4.5 4.5 3z"/></svg>
      <span itemprop="name">Code</span>
      <meta itemprop="position" content="1">
</a>  </span>

    <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
      <a itemprop="url" data-hotkey="g i" class="js-selected-navigation-item reponav-item" data-selected-links="repo_issues repo_labels repo_milestones /jbhuang0604/awesome-computer-vision/issues" href="/jbhuang0604/awesome-computer-vision/issues">
        <svg class="octicon octicon-issue-opened" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg>
        <span itemprop="name">Issues</span>
        <span class="Counter">9</span>
        <meta itemprop="position" content="2">
</a>    </span>

  <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
    <a data-hotkey="g p" itemprop="url" class="js-selected-navigation-item reponav-item" data-selected-links="repo_pulls checks /jbhuang0604/awesome-computer-vision/pulls" href="/jbhuang0604/awesome-computer-vision/pulls">
      <svg class="octicon octicon-git-pull-request" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M11 11.28V5c-.03-.78-.34-1.47-.94-2.06C9.46 2.35 8.78 2.03 8 2H7V0L4 3l3 3V4h1c.27.02.48.11.69.31.21.2.3.42.31.69v6.28A1.993 1.993 0 0 0 10 15a1.993 1.993 0 0 0 1-3.72zm-1 2.92c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zM4 3c0-1.11-.89-2-2-2a1.993 1.993 0 0 0-1 3.72v6.56A1.993 1.993 0 0 0 2 15a1.993 1.993 0 0 0 1-3.72V4.72c.59-.34 1-.98 1-1.72zm-.8 10c0 .66-.55 1.2-1.2 1.2-.65 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2zM2 4.2C1.34 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z"/></svg>
      <span itemprop="name">Pull requests</span>
      <span class="Counter">15</span>
      <meta itemprop="position" content="3">
</a>  </span>

    <a data-hotkey="g b" class="js-selected-navigation-item reponav-item" data-selected-links="repo_projects new_repo_project repo_project /jbhuang0604/awesome-computer-vision/projects" href="/jbhuang0604/awesome-computer-vision/projects">
      <svg class="octicon octicon-project" viewBox="0 0 15 16" version="1.1" width="15" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 12h3V2h-3v10zm-4-2h3V2H6v8zm-4 4h3V2H2v12zm-1 1h13V1H1v14zM14 0H1a1 1 0 0 0-1 1v14a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1V1a1 1 0 0 0-1-1z"/></svg>
      Projects
      <span class="Counter" >0</span>
</a>
    <a class="js-selected-navigation-item reponav-item" data-hotkey="g w" data-selected-links="repo_wiki /jbhuang0604/awesome-computer-vision/wiki" href="/jbhuang0604/awesome-computer-vision/wiki">
      <svg class="octicon octicon-book" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M3 5h4v1H3V5zm0 3h4V7H3v1zm0 2h4V9H3v1zm11-5h-4v1h4V5zm0 2h-4v1h4V7zm0 2h-4v1h4V9zm2-6v9c0 .55-.45 1-1 1H9.5l-1 1-1-1H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h5.5l1 1 1-1H15c.55 0 1 .45 1 1zm-8 .5L7.5 3H2v9h6V3.5zm7-.5H9.5l-.5.5V12h6V3z"/></svg>
      Wiki
</a>

  <a class="js-selected-navigation-item reponav-item" data-selected-links="repo_graphs repo_contributors dependency_graph pulse /jbhuang0604/awesome-computer-vision/pulse" href="/jbhuang0604/awesome-computer-vision/pulse">
    <svg class="octicon octicon-graph" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M16 14v1H0V0h1v14h15zM5 13H3V8h2v5zm4 0H7V3h2v10zm4 0h-2V6h2v7z"/></svg>
    Insights
</a>

</nav>


  </div>

<div class="container new-discussion-timeline experiment-repo-nav  ">
  <div class="repository-content ">

    
  

  <div class="js-repo-meta-container">
  <div class="repository-meta mb-0 mb-3 js-repo-meta-edit js-details-container ">
    <div class="repository-meta-content col-11 mb-1">
          <span class="col-11 text-gray-dark mr-2" itemprop="about">
            A curated list of awesome computer vision resources
          </span>
    </div>

  </div>

</div>



  <div class="overall-summary ">
    <div class="stats-switcher-viewport js-stats-switcher-viewport">
      <div class="stats-switcher-wrapper">
      <ul class="numbers-summary">
        <li class="commits">
          <a data-pjax href="/jbhuang0604/awesome-computer-vision/commits/master">
              <svg class="octicon octicon-history" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 13H6V6h5v2H8v5zM7 1C4.81 1 2.87 2.02 1.59 3.59L0 2v4h4L2.5 4.5C3.55 3.17 5.17 2.3 7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-.34.03-.67.09-1H.08C.03 7.33 0 7.66 0 8c0 3.86 3.14 7 7 7s7-3.14 7-7-3.14-7-7-7z"/></svg>
              <span class="num text-emphasized">
                184
              </span>
              commits
          </a>
        </li>
        <li>
          <a data-pjax href="/jbhuang0604/awesome-computer-vision/branches">
            <svg class="octicon octicon-git-branch" viewBox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 5c0-1.11-.89-2-2-2a1.993 1.993 0 0 0-1 3.72v.3c-.02.52-.23.98-.63 1.38-.4.4-.86.61-1.38.63-.83.02-1.48.16-2 .45V4.72a1.993 1.993 0 0 0-1-3.72C.88 1 0 1.89 0 3a2 2 0 0 0 1 1.72v6.56c-.59.35-1 .99-1 1.72 0 1.11.89 2 2 2 1.11 0 2-.89 2-2 0-.53-.2-1-.53-1.36.09-.06.48-.41.59-.47.25-.11.56-.17.94-.17 1.05-.05 1.95-.45 2.75-1.25S8.95 7.77 9 6.73h-.02C9.59 6.37 10 5.73 10 5zM2 1.8c.66 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2C1.35 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2zm0 12.41c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zm6-8c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z"/></svg>
            <span class="num text-emphasized">
              1
            </span>
            branch
          </a>
        </li>

        <li>
          <a href="/jbhuang0604/awesome-computer-vision/releases">
            <svg class="octicon octicon-tag" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.685 1.72a2.49 2.49 0 0 0-1.76-.726H3.48A2.5 2.5 0 0 0 .994 3.48v2.456c0 .656.269 1.292.726 1.76l6.024 6.024a.99.99 0 0 0 1.402 0l4.563-4.563a.99.99 0 0 0 0-1.402L7.685 1.72zM2.366 7.048A1.54 1.54 0 0 1 1.9 5.925V3.48c0-.874.716-1.58 1.58-1.58h2.456c.418 0 .825.159 1.123.467l6.104 6.094-4.702 4.702-6.094-6.114zm.626-4.066h1.989v1.989H2.982V2.982h.01z"/></svg>
            <span class="num text-emphasized">
              0
            </span>
            releases
          </a>
        </li>

        <li>
            <a href="/jbhuang0604/awesome-computer-vision/graphs/contributors">
  <svg class="octicon octicon-organization" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M16 12.999c0 .439-.45 1-1 1H7.995c-.539 0-.994-.447-.995-.999H1c-.54 0-1-.561-1-1 0-2.634 3-4 3-4s.229-.409 0-1c-.841-.621-1.058-.59-1-3 .058-2.419 1.367-3 2.5-3s2.442.58 2.5 3c.058 2.41-.159 2.379-1 3-.229.59 0 1 0 1s1.549.711 2.42 2.088C9.196 9.369 10 8.999 10 8.999s.229-.409 0-1c-.841-.62-1.058-.59-1-3 .058-2.419 1.367-3 2.5-3s2.437.581 2.495 3c.059 2.41-.158 2.38-1 3-.229.59 0 1 0 1s3.005 1.366 3.005 4z"/></svg>
    <span class="num text-emphasized">
      23
    </span>
    contributors
</a>

        </li>
      </ul>

      </div>
    </div>
  </div>



    <include-fragment src="/jbhuang0604/awesome-computer-vision/show_partial?partial=tree%2Frecently_touched_branches_list"></include-fragment>

  <div class="file-navigation in-mid-page">

    <details class="get-repo-select-menu js-get-repo-select-menu float-right position-relative dropdown-details details-reset">
  <summary class="btn btn-sm btn-primary">
    Clone or download
    <span class="dropdown-caret"></span>
  </summary>
  <div class="position-relative">
    <div class="get-repo-modal dropdown-menu dropdown-menu-sw pb-0 js-toggler-container  js-get-repo-modal">

      <div class="get-repo-modal-options">
          <div class="clone-options https-clone-options">
              <!-- '"` --><!-- </textarea></xmp> --></option></form><form data-remote="true" action="/users/set_protocol?protocol_selector=ssh&amp;protocol_type=clone" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="rXcnXEgp/2FZzf3faKB7YxF7qksZ15nEU6gz5dPTS85xxjvczK/KGNBmlbwR+FPKEbUtnUbi9MqC6DcaqEB6sg==" /><button type="submit" class="btn-link btn-change-protocol js-toggler-target float-right">Use SSH</button></form>

            <h4 class="mb-1">
              Clone with HTTPS
              <a class="muted-link" href="https://help.github.com/articles/which-remote-url-should-i-use" target="_blank" title="Which remote URL should I use?">
                <svg class="octicon octicon-question" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6 10h2v2H6v-2zm4-3.5C10 8.64 8 9 8 9H6c0-.55.45-1 1-1h.5c.28 0 .5-.22.5-.5v-1c0-.28-.22-.5-.5-.5h-1c-.28 0-.5.22-.5.5V7H4c0-1.5 1.5-3 3-3s3 1 3 2.5zM7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7z"/></svg>
              </a>
            </h4>
            <p class="mb-2 get-repo-decription-text">
              Use Git or checkout with SVN using the web URL.
            </p>

            <div class="input-group">
  <input type="text" class="form-control input-monospace input-sm js-url-field" value="https://github.com/jbhuang0604/awesome-computer-vision.git" aria-label="Clone this repository at https://github.com/jbhuang0604/awesome-computer-vision.git" readonly>
  <div class="input-group-button">
    <clipboard-copy value="https://github.com/jbhuang0604/awesome-computer-vision.git" aria-label="Copy to clipboard" class="btn btn-sm">
      <svg class="octicon octicon-clippy" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2 13h4v1H2v-1zm5-6H2v1h5V7zm2 3V8l-3 3 3 3v-2h5v-2H9zM4.5 9H2v1h2.5V9zM2 12h2.5v-1H2v1zm9 1h1v2c-.02.28-.11.52-.3.7-.19.18-.42.28-.7.3H1c-.55 0-1-.45-1-1V4c0-.55.45-1 1-1h3c0-1.11.89-2 2-2 1.11 0 2 .89 2 2h3c.55 0 1 .45 1 1v5h-1V6H1v9h10v-2zM2 5h8c0-.55-.45-1-1-1H8c-.55 0-1-.45-1-1s-.45-1-1-1-1 .45-1 1-.45 1-1 1H3c-.55 0-1 .45-1 1z"/></svg>
    </clipboard-copy>
  </div>
</div>

          </div>

          <div class="clone-options ssh-clone-options">
              <!-- '"` --><!-- </textarea></xmp> --></option></form><form data-remote="true" action="/users/set_protocol?protocol_selector=https&amp;protocol_type=clone" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="5+d2/2iOZ87V80KTdjrt/WuvXzgTHmFw/KY3zc8ILb87Vmp/7AhSt1xYKvAPYsVUa2HY7kwrDH4t5jMytJscww==" /><button type="submit" class="btn-link btn-change-protocol js-toggler-target float-right">Use HTTPS</button></form>

              <h4 class="mb-1">
                Clone with SSH
                <a class="muted-link" href="https://help.github.com/articles/which-remote-url-should-i-use" target="_blank" title="Which remote URL should I use?">
                  <svg class="octicon octicon-question" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6 10h2v2H6v-2zm4-3.5C10 8.64 8 9 8 9H6c0-.55.45-1 1-1h.5c.28 0 .5-.22.5-.5v-1c0-.28-.22-.5-.5-.5h-1c-.28 0-.5.22-.5.5V7H4c0-1.5 1.5-3 3-3s3 1 3 2.5zM7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7z"/></svg>
                </a>
              </h4>
              <p class="mb-2 get-repo-decription-text">
                Use an SSH key and passphrase from account.
              </p>

              <div class="input-group">
  <input type="text" class="form-control input-monospace input-sm js-url-field" value="git@github.com:jbhuang0604/awesome-computer-vision.git" aria-label="Clone this repository at git@github.com:jbhuang0604/awesome-computer-vision.git" readonly>
  <div class="input-group-button">
    <clipboard-copy value="git@github.com:jbhuang0604/awesome-computer-vision.git" aria-label="Copy to clipboard" class="btn btn-sm">
      <svg class="octicon octicon-clippy" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2 13h4v1H2v-1zm5-6H2v1h5V7zm2 3V8l-3 3 3 3v-2h5v-2H9zM4.5 9H2v1h2.5V9zM2 12h2.5v-1H2v1zm9 1h1v2c-.02.28-.11.52-.3.7-.19.18-.42.28-.7.3H1c-.55 0-1-.45-1-1V4c0-.55.45-1 1-1h3c0-1.11.89-2 2-2 1.11 0 2 .89 2 2h3c.55 0 1 .45 1 1v5h-1V6H1v9h10v-2zM2 5h8c0-.55-.45-1-1-1H8c-.55 0-1-.45-1-1s-.45-1-1-1-1 .45-1 1-.45 1-1 1H3c-.55 0-1 .45-1 1z"/></svg>
    </clipboard-copy>
  </div>
</div>

          </div>
        <div class="mt-2">
            <a href="x-github-client://openRepo/https://github.com/jbhuang0604/awesome-computer-vision" class="btn btn-outline get-repo-btn tooltipped tooltipped-s tooltipped-multiline js-get-repo" data-open-app="windows" aria-label="Clone jbhuang0604/awesome-computer-vision to your computer and use it in GitHub Desktop.">
    Open in Desktop
  </a>

<a href="/jbhuang0604/awesome-computer-vision/archive/master.zip"
   class="btn btn-outline get-repo-btn
"
   rel="nofollow"
   data-ga-click="Repository, download zip, location:repo overview">
  Download ZIP
</a>

        </div>
      </div>

      <div class="js-modal-download-mac py-2 px-3 d-none">
        <h4 class="lh-condensed mb-3">Launching GitHub Desktop<span class="animated-ellipsis-container"><span class="animated-ellipsis">...</span></span></h4>
        <p class="text-gray">If nothing happens, <a href="https://desktop.github.com/">download GitHub Desktop</a> and try again.</p>
        <p><button class="btn-link js-get-repo-modal-download-back">Go back</button></p>
      </div>

      <div class="js-modal-download-windows py-2 px-3 d-none">
        <h4 class="lh-condensed mb-3">Launching GitHub Desktop<span class="animated-ellipsis-container"><span class="animated-ellipsis">...</span></span></h4>
        <p class="text-gray">If nothing happens, <a href="https://desktop.github.com/">download GitHub Desktop</a> and try again.</p>
        <p><button class="btn-link js-get-repo-modal-download-back">Go back</button></p>
      </div>

      <div class="js-modal-download-xcode py-2 px-3 d-none">
        <h4 class="lh-condensed mb-3">Launching Xcode<span class="animated-ellipsis-container"><span class="animated-ellipsis">...</span></span></h4>
        <p class="text-gray">If nothing happens, <a href="https://developer.apple.com/xcode/">download Xcode</a> and try again.</p>
        <p><button class="btn-link js-get-repo-modal-download-back">Go back</button></p>
      </div>

      <div class="js-modal-download-visual-studio py-2 px-3 d-none">
        <h4 class="lh-condensed mb-3">Launching Visual Studio<span class="animated-ellipsis-container"><span class="animated-ellipsis">...</span></span></h4>
        <p class="text-gray">If nothing happens, <a href="https://visualstudio.github.com/">download the GitHub extension for Visual Studio</a> and try again.</p>
        <p><button class="btn-link js-get-repo-modal-download-back">Go back</button></p>
      </div>

    </div>
  </div>
</details>


  <div class="BtnGroup float-right">
      
  <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="BtnGroup-form" action="/jbhuang0604/awesome-computer-vision/new/master" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="gaTILc1+VHadKD56BD+I6JKGO1f4en1lsJtekbUsVGUo/pUBg+VlEqtroflBSMV/BMq2lLZ5d0uZ5d+DzYUL2w==" />
    <button class="btn btn-sm BtnGroup-item" type="submit" data-disable-with="Creating file…">
      Create new file
    </button>
</form>

      
  <a href="/jbhuang0604/awesome-computer-vision/upload/master" class="btn btn-sm BtnGroup-item">
    Upload files
  </a>


    <a href="/jbhuang0604/awesome-computer-vision/find/master"
      class="btn btn-sm empty-icon float-right BtnGroup-item"
      data-pjax
      data-hotkey="t"
      data-ga-click="Repository, find file, location:repo overview">
      Find file
    </a>
  </div>

  
<div class="select-menu branch-select-menu js-menu-container js-select-menu float-left">
  <button class=" btn btn-sm select-menu-button js-menu-target css-truncate" data-hotkey="w"
    
    type="button" aria-label="Switch branches or tags" aria-expanded="false" aria-haspopup="true">
      <i>Branch:</i>
      <span class="js-select-button css-truncate-target">master</span>
  </button>

  <div class="select-menu-modal-holder js-menu-content js-navigation-container" data-pjax>

    <div class="select-menu-modal">
      <div class="select-menu-header">
        <svg class="octicon octicon-x js-menu-close" role="img" aria-label="Close" viewBox="0 0 12 16" version="1.1" width="12" height="16"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48L7.48 8z"/></svg>
        <span class="select-menu-title">Switch branches/tags</span>
      </div>

      <div class="select-menu-filters">
        <div class="select-menu-text-filter">
          <input type="text" aria-label="Filter branches/tags" id="context-commitish-filter-field" class="form-control js-filterable-field js-navigation-enable" placeholder="Filter branches/tags">
        </div>
        <div class="select-menu-tabs">
          <ul>
            <li class="select-menu-tab">
              <a href="#" data-tab-filter="branches" data-filter-placeholder="Filter branches/tags" class="js-select-menu-tab" role="tab">Branches</a>
            </li>
            <li class="select-menu-tab">
              <a href="#" data-tab-filter="tags" data-filter-placeholder="Find a tag…" class="js-select-menu-tab" role="tab">Tags</a>
            </li>
          </ul>
        </div>
      </div>

      <div class="select-menu-list select-menu-tab-bucket js-select-menu-tab-bucket" data-tab-filter="branches" role="menu">

        <div data-filterable-for="context-commitish-filter-field" data-filterable-type="substring">


            <a class="select-menu-item js-navigation-item js-navigation-open selected"
               href="/jbhuang0604/awesome-computer-vision/tree/master"
               data-name="master"
               data-skip-pjax="true"
               rel="nofollow">
              <svg class="octicon octicon-check select-menu-item-icon" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5L12 5z"/></svg>
              <span class="select-menu-item-text css-truncate-target js-select-menu-filter-text">
                master
              </span>
            </a>
        </div>

          <div class="select-menu-no-results">Nothing to show</div>
      </div>

      <div class="select-menu-list select-menu-tab-bucket js-select-menu-tab-bucket" data-tab-filter="tags">
        <div data-filterable-for="context-commitish-filter-field" data-filterable-type="substring">


        </div>

        <div class="select-menu-no-results">Nothing to show</div>
      </div>

    </div>
  </div>
</div>


        <a href="/jbhuang0604/awesome-computer-vision/pull/new/master" class="btn btn-sm new-pull-request-btn" data-pjax data-ga-click="Repository, new pull request, location:repo overview">
          New pull request
        </a>

  <div class="breadcrumb">
    
  </div>
</div>


  


  <div class="commit-tease js-details-container Details">
    <span class="float-right">
      Latest commit
      <a class="commit-tease-sha" href="/jbhuang0604/awesome-computer-vision/commit/f889c45852613014201662ba94e3bb2d4d369206" data-pjax>
        f889c45
      </a>
      <span itemprop="dateModified"><relative-time datetime="2018-01-21T21:08:27Z">Jan 22, 2018</relative-time></span>
    </span>


      <div class="d-flex no-wrap">
        
<div class="AvatarStack flex-self-start ">
  <div class="AvatarStack-body tooltipped tooltipped-se tooltipped-align-left-1"
       aria-label="jbhuang0604">

        <a href="/jbhuang0604" data-skip-pjax="true" class="avatar">
          <img src="https://avatars3.githubusercontent.com/u/987204?s=40&amp;v=4" width="20" height="20" alt="@jbhuang0604">
        </a>
  </div>
</div>

        <div class="flex-auto f6">
          
      <a href="/jbhuang0604/awesome-computer-vision/commits?author=jbhuang0604"
     class="commit-author tooltipped tooltipped-s user-mention"
     aria-label="View all commits by jbhuang0604">jbhuang0604</a>


  committed
  <relative-time datetime="2018-01-21T21:08:27Z">Jan 22, 2018</relative-time>



      <a href="/jbhuang0604/awesome-computer-vision/commit/f889c45852613014201662ba94e3bb2d4d369206" class="message" data-pjax="true" title="Update README.md">Update README.md</a>


        </div>
      </div>
  </div>



<div class="file-wrap">

  <a class="d-none js-permalink-shortcut" data-hotkey="y" href="/jbhuang0604/awesome-computer-vision/tree/f889c45852613014201662ba94e3bb2d4d369206">Permalink</a>

  <table class="files js-navigation-container js-active-navigation-container" data-pjax>


    <tbody>
      <tr class="warning include-fragment-error">
        <td class="icon"><svg class="octicon octicon-alert" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"/></svg></td>
        <td class="content" colspan="3">Failed to load latest commit information.</td>
      </tr>

        <tr class="js-navigation-item">
          <td class="icon">
            <svg class="octicon octicon-file" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6 5H2V4h4v1zM2 8h7V7H2v1zm0 2h7V9H2v1zm0 2h7v-1H2v1zm10-7.5V14c0 .55-.45 1-1 1H1c-.55 0-1-.45-1-1V2c0-.55.45-1 1-1h7.5L12 4.5zM11 5L8 2H1v12h10V5z"/></svg>
            <img width="16" height="16" class="spinner" alt="" src="https://assets-cdn.github.com/images/spinners/octocat-spinner-32.gif" />
          </td>
          <td class="content">
            <span class="css-truncate css-truncate-target"><a class="js-navigation-open" title="README.md" id="04c6e90faac2675aa89e2176d2eec7d8-845e0004fd4c2ab4d68fb1c4973a673658c94806" href="/jbhuang0604/awesome-computer-vision/blob/master/README.md">README.md</a></span>
          </td>
          <td class="message">
            <span class="css-truncate css-truncate-target">
                  <a data-pjax="true" title="Update README.md" class="message" href="/jbhuang0604/awesome-computer-vision/commit/f889c45852613014201662ba94e3bb2d4d369206">Update README.md</a>
            </span>
          </td>
          <td class="age">
            <span class="css-truncate css-truncate-target"><time-ago datetime="2018-01-21T21:08:27Z">Jan 22, 2018</time-ago></span>
          </td>
        </tr>
        <tr class="js-navigation-item">
          <td class="icon">
            <svg class="octicon octicon-file" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6 5H2V4h4v1zM2 8h7V7H2v1zm0 2h7V9H2v1zm0 2h7v-1H2v1zm10-7.5V14c0 .55-.45 1-1 1H1c-.55 0-1-.45-1-1V2c0-.55.45-1 1-1h7.5L12 4.5zM11 5L8 2H1v12h10V5z"/></svg>
            <img width="16" height="16" class="spinner" alt="" src="https://assets-cdn.github.com/images/spinners/octocat-spinner-32.gif" />
          </td>
          <td class="content">
            <span class="css-truncate css-truncate-target"><a class="js-navigation-open" title="people.md" id="409d35e455283866f433512e0ab60fb9-790739d9d83be73ebbd507562c77034461de51b9" href="/jbhuang0604/awesome-computer-vision/blob/master/people.md">people.md</a></span>
          </td>
          <td class="message">
            <span class="css-truncate css-truncate-target">
                  <a data-pjax="true" title="remove a redundant &quot;[&quot;" class="message" href="/jbhuang0604/awesome-computer-vision/commit/d100850feae0a3938b11a1976ef7f93778876823">remove a redundant "["</a>
            </span>
          </td>
          <td class="age">
            <span class="css-truncate css-truncate-target"><time-ago datetime="2015-01-20T17:56:54Z">Jan 20, 2015</time-ago></span>
          </td>
        </tr>
    </tbody>
  </table>

</div>



  <div id="readme" class="readme boxed-group clearfix announce instapaper_body md">
    <h3>
      <svg class="octicon octicon-book" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M3 5h4v1H3V5zm0 3h4V7H3v1zm0 2h4V9H3v1zm11-5h-4v1h4V5zm0 2h-4v1h4V7zm0 2h-4v1h4V9zm2-6v9c0 .55-.45 1-1 1H9.5l-1 1-1-1H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h5.5l1 1 1-1H15c.55 0 1 .45 1 1zm-8 .5L7.5 3H2v9h6V3.5zm7-.5H9.5l-.5.5V12h6V3z"/></svg>
      README.md
    </h3>

      <article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-awesome-computer-vision-" class="anchor" aria-hidden="true" href="#awesome-computer-vision-"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Awesome Computer Vision: <a href="https://github.com/sindresorhus/awesome"><img src="https://camo.githubusercontent.com/13c4e50d88df7178ae1882a203ed57b641674f94/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667" alt="Awesome" data-canonical-src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" style="max-width:100%;"></a></h1>
<p>A curated list of awesome computer vision resources, inspired by <a href="https://github.com/ziadoz/awesome-php">awesome-php</a>.</p>
<p>For a list people in computer vision listed with their academic genealogy, please visit <a href="https://github.com/jbhuang0604/awesome-computer-vision/blob/master/people.md">here</a></p>
<h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Contributing</h2>
<p>Please feel free to send me <a href="https://github.com/jbhuang0604/awesome-computer-vision/pulls">pull requests</a> or email (<a href="mailto:jbhuang1@illinois.edu">jbhuang1@illinois.edu</a>) to add links.</p>
<h2><a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Table of Contents</h2>
<ul>
<li><a href="#books">Books</a></li>
<li><a href="#courses">Courses</a></li>
<li><a href="#papers">Papers</a></li>
<li><a href="#software">Software</a></li>
<li><a href="#datasets">Datasets</a></li>
<li><a href="#tutorials-and-talks">Tutorials and Talks</a></li>
<li><a href="#resources-for-students">Resources for students</a></li>
<li><a href="#blogs">Blogs</a></li>
<li><a href="#links">Links</a></li>
<li><a href="#songs">Songs</a></li>
</ul>
<h2><a id="user-content-books" class="anchor" aria-hidden="true" href="#books"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Books</h2>
<h4><a id="user-content-computer-vision" class="anchor" aria-hidden="true" href="#computer-vision"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Computer Vision</h4>
<ul>
<li><a href="http://www.computervisionmodels.com/" rel="nofollow">Computer Vision:  Models, Learning, and Inference</a> - Simon J. D. Prince 2012</li>
<li><a href="http://szeliski.org/Book/" rel="nofollow">Computer Vision: Theory and Application</a> - Rick Szeliski 2010</li>
<li><a href="http://www.amazon.com/Computer-Vision-Modern-Approach-2nd/dp/013608592X/ref=dp_ob_title_bk" rel="nofollow">Computer Vision: A Modern Approach (2nd edition)</a> - David Forsyth and Jean Ponce 2011</li>
<li><a href="http://www.robots.ox.ac.uk/%7Evgg/hzbook/" rel="nofollow">Multiple View Geometry in Computer Vision</a> - Richard Hartley and Andrew Zisserman 2004</li>
<li><a href="http://www.amazon.com/Computer-Vision-Linda-G-Shapiro/dp/0130307963" rel="nofollow">Computer Vision</a> - Linda G. Shapiro 2001</li>
<li><a href="http://www.amazon.com/Vision-Science-Phenomenology-Stephen-Palmer/dp/0262161834/" rel="nofollow">Vision Science: Photons to Phenomenology</a> - Stephen E. Palmer 1999</li>
<li><a href="http://www.morganclaypool.com/doi/abs/10.2200/S00332ED1V01Y201103AIM011" rel="nofollow">Visual Object Recognition synthesis lecture</a> - Kristen Grauman and Bastian Leibe 2011</li>
<li><a href="http://cvfxbook.com/" rel="nofollow">Computer Vision for Visual Effects</a> - Richard J. Radke, 2012</li>
<li><a href="http://www.amazon.com/High-Dynamic-Range-Imaging-Second/dp/012374914X" rel="nofollow">High dynamic range imaging: acquisition, display, and image-based lighting</a> - Reinhard, E., Heidrich, W., Debevec, P., Pattanaik, S., Ward, G., Myszkowski, K 2010</li>
<li><a href="https://people.csail.mit.edu/jsolomon/share/book/numerical_book.pdf" rel="nofollow">Numerical Algorithms: Methods for Computer Vision, Machine Learning, and Graphics</a> - Justin Solomon 2015</li>
</ul>
<h4><a id="user-content-opencv-programming" class="anchor" aria-hidden="true" href="#opencv-programming"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>OpenCV Programming</h4>
<ul>
<li><a href="http://www.amazon.com/Learning-OpenCV-Computer-Vision-Library/dp/0596516134" rel="nofollow">Learning OpenCV: Computer Vision with the OpenCV Library</a> - Gary Bradski and Adrian Kaehler</li>
<li><a href="https://www.pyimagesearch.com/practical-python-opencv/" rel="nofollow">Practical Python and OpenCV</a> - Adrian Rosebrock</li>
<li><a href="http://www.amazon.com/OpenCV-Essentials-Oscar-Deniz-Suarez/dp/1783984244/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1424594237&amp;sr=1-1&amp;keywords=opencv+essentials#" rel="nofollow">OpenCV Essentials</a> - Oscar Deniz Suarez, Mª del Milagro Fernandez Carrobles, Noelia Vallez Enano, Gloria Bueno Garcia, Ismael Serrano Gracia</li>
</ul>
<h4><a id="user-content-machine-learning" class="anchor" aria-hidden="true" href="#machine-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Machine Learning</h4>
<ul>
<li><a href="http://research.microsoft.com/en-us/um/people/cmbishop/prml/index.htm" rel="nofollow">Pattern Recognition and Machine Learning</a> - Christopher M. Bishop 2007</li>
<li><a href="http://www.engineering.upm.ro/master-ie/sacpi/mat_did/info068/docum/Neural%20Networks%20for%20Pattern%20Recognition.pdf" rel="nofollow">Neural Networks for Pattern Recognition</a> - Christopher M. Bishop 1995</li>
<li><a href="http://pgm.stanford.edu/" rel="nofollow">Probabilistic Graphical Models: Principles and Techniques</a> - Daphne Koller and Nir Friedman 2009</li>
<li><a href="http://www.amazon.com/Pattern-Classification-2nd-Richard-Duda/dp/0471056693" rel="nofollow">Pattern Classification</a> - Peter E. Hart, David G. Stork, and Richard O. Duda 2000</li>
<li><a href="http://www.amazon.com/Machine-Learning-Tom-M-Mitchell/dp/0070428077/" rel="nofollow">Machine Learning</a> - Tom M. Mitchell 1997</li>
<li><a href="http://www.gaussianprocess.org/gpml/" rel="nofollow">Gaussian processes for machine learning</a> - Carl Edward Rasmussen and Christopher K. I. Williams 2005</li>
<li><a href="https://work.caltech.edu/telecourse.html" rel="nofollow">Learning From Data</a>- Yaser S. Abu-Mostafa, Malik Magdon-Ismail and Hsuan-Tien Lin 2012</li>
<li><a href="http://neuralnetworksanddeeplearning.com/" rel="nofollow">Neural Networks and Deep Learning</a> - Michael Nielsen 2014</li>
<li><a href="http://www.cs.ucl.ac.uk/staff/d.barber/brml/" rel="nofollow">Bayesian Reasoning and Machine Learning</a> - David Barber, Cambridge University Press, 2012</li>
</ul>
<h4><a id="user-content-fundamentals" class="anchor" aria-hidden="true" href="#fundamentals"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fundamentals</h4>
<ul>
<li><a href="http://www.amazon.com/Linear-Algebra-Its-Applications-4th/dp/0030105676/ref=sr_1_4?ie=UTF8&amp;qid=1421433773&amp;sr=8-4&amp;keywords=Linear+Algebra+and+Its+Applications" rel="nofollow">Linear Algebra and Its Applications</a> - Gilbert Strang 1995</li>
</ul>
<h2><a id="user-content-courses" class="anchor" aria-hidden="true" href="#courses"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Courses</h2>
<h4><a id="user-content-computer-vision-1" class="anchor" aria-hidden="true" href="#computer-vision-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Computer Vision</h4>
<ul>
<li><a href="http://inside.mines.edu/%7Ewhoff/courses/EENG512/" rel="nofollow">EENG 512 / CSCI 512 - Computer Vision</a> - William Hoff (Colorado School of Mines)</li>
<li><a href="https://sites.google.com/site/ucbcs29443/" rel="nofollow">Visual Object and Activity Recognition</a> - Alexei A. Efros and Trevor Darrell (UC Berkeley)</li>
<li><a href="http://courses.cs.washington.edu/courses/cse455/12wi/" rel="nofollow">Computer Vision</a> - Steve Seitz (University of Washington)</li>
<li>Visual Recognition <a href="http://vision.cs.utexas.edu/381V-spring2016/" rel="nofollow">Spring 2016</a>, <a href="http://vision.cs.utexas.edu/381V-fall2016/" rel="nofollow">Fall 2016</a> - Kristen Grauman (UT Austin)</li>
<li><a href="http://www.tamaraberg.com/teaching/Spring_15/" rel="nofollow">Language and Vision</a> - Tamara Berg (UNC Chapel Hill)</li>
<li><a href="http://vision.stanford.edu/teaching/cs231n/" rel="nofollow">Convolutional Neural Networks for Visual Recognition</a> - Fei-Fei Li and Andrej Karpathy (Stanford University)</li>
<li><a href="http://cs.nyu.edu/%7Efergus/teaching/vision/index.html" rel="nofollow">Computer Vision</a> - Rob Fergus (NYU)</li>
<li><a href="https://courses.engr.illinois.edu/cs543/sp2015/" rel="nofollow">Computer Vision</a> - Derek Hoiem (UIUC)</li>
<li><a href="http://vision.stanford.edu/teaching/cs131_fall1415/index.html" rel="nofollow">Computer Vision: Foundations and Applications</a> - Kalanit Grill-Spector and Fei-Fei Li (Stanford University)</li>
<li><a href="http://vision.stanford.edu/teaching/cs431_spring1314/" rel="nofollow">High-Level Vision: Behaviors, Neurons and Computational Models</a> - Fei-Fei Li (Stanford University)</li>
<li><a href="http://6.869.csail.mit.edu/fa15/" rel="nofollow">Advances in Computer Vision</a> - Antonio Torralba and Bill Freeman (MIT)</li>
<li><a href="http://www.vision.rwth-aachen.de/course/11/" rel="nofollow">Computer Vision</a> - Bastian Leibe (RWTH Aachen University)</li>
<li><a href="http://www.vision.rwth-aachen.de/course/9/" rel="nofollow">Computer Vision 2</a> - Bastian Leibe (RWTH Aachen University)</li>
<li><a href="http://klewel.com/conferences/epfl-computer-vision/" rel="nofollow">Computer Vision</a> Pascal Fua (EPFL):</li>
<li><a href="http://cvlab-dresden.de/courses/computer-vision-1/" rel="nofollow">Computer Vision 1</a> Carsten Rother (TU Dresden):</li>
<li><a href="http://cvlab-dresden.de/courses/CV2/" rel="nofollow">Computer Vision 2</a> Carsten Rother (TU Dresden):</li>
<li><a href="https://youtu.be/RDkwklFGMfo?list=PLTBdjV_4f-EJn6udZ34tht9EVIW7lbeo4" rel="nofollow">Multiple View Geometry</a> Daniel Cremers (TU Munich):</li>
</ul>
<h4><a id="user-content-computational-photography" class="anchor" aria-hidden="true" href="#computational-photography"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Computational Photography</h4>
<ul>
<li><a href="http://inst.eecs.berkeley.edu/%7Ecs194-26/fa14/" rel="nofollow">Image Manipulation and Computational Photography</a> - Alexei A. Efros (UC Berkeley)</li>
<li><a href="http://graphics.cs.cmu.edu/courses/15-463/2012_fall/463.html" rel="nofollow">Computational Photography</a> - Alexei A. Efros (CMU)</li>
<li><a href="https://courses.engr.illinois.edu/cs498dh3/" rel="nofollow">Computational Photography</a> - Derek Hoiem (UIUC)</li>
<li><a href="http://cs.brown.edu/courses/csci1290/" rel="nofollow">Computational Photography</a> - James Hays (Brown University)</li>
<li><a href="http://stellar.mit.edu/S/course/6/sp12/6.815/" rel="nofollow">Digital &amp; Computational Photography</a> - Fredo Durand (MIT)</li>
<li><a href="http://ocw.mit.edu/courses/media-arts-and-sciences/mas-531-computational-camera-and-photography-fall-2009/" rel="nofollow">Computational Camera and Photography</a> - Ramesh Raskar (MIT Media Lab)</li>
<li><a href="https://www.udacity.com/course/computational-photography--ud955" rel="nofollow">Computational Photography</a> - Irfan Essa (Georgia Tech)</li>
<li><a href="http://graphics.stanford.edu/courses/" rel="nofollow">Courses in Graphics</a> - Stanford University</li>
<li><a href="http://cs.nyu.edu/%7Efergus/teaching/comp_photo/index.html" rel="nofollow">Computational Photography</a> - Rob Fergus (NYU)</li>
<li><a href="http://www.cs.toronto.edu/%7Ekyros/courses/320/" rel="nofollow">Introduction to Visual Computing</a> - Kyros Kutulakos (University of Toronto)</li>
<li><a href="http://www.cs.toronto.edu/%7Ekyros/courses/2530/" rel="nofollow">Computational Photography</a> - Kyros Kutulakos (University of Toronto)</li>
<li><a href="https://www.ecse.rpi.edu/%7Erjradke/cvfxcourse.html" rel="nofollow">Computer Vision for Visual Effects</a> - Rich Radke (Rensselaer Polytechnic Institute)</li>
<li><a href="https://www.ecse.rpi.edu/%7Erjradke/improccourse.html" rel="nofollow">Introduction to Image Processing</a> - Rich Radke (Rensselaer Polytechnic Institute)</li>
</ul>
<h4><a id="user-content-machine-learning-and-statistical-learning" class="anchor" aria-hidden="true" href="#machine-learning-and-statistical-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Machine Learning and Statistical Learning</h4>
<ul>
<li><a href="https://www.coursera.org/learn/machine-learning" rel="nofollow">Machine Learning</a> - Andrew Ng (Stanford University)</li>
<li><a href="https://work.caltech.edu/telecourse.html" rel="nofollow">Learning from Data</a> - Yaser S. Abu-Mostafa (Caltech)</li>
<li><a href="https://class.stanford.edu/courses/HumanitiesandScience/StatLearning/Winter2015/about" rel="nofollow">Statistical Learning</a> - Trevor Hastie and Rob Tibshirani (Stanford University)</li>
<li><a href="http://www.mit.edu/%7E9.520/fall14/" rel="nofollow">Statistical Learning Theory and Applications</a> - Tomaso Poggio, Lorenzo Rosasco, Carlo Ciliberto, Charlie Frogner, Georgios Evangelopoulos, Ben Deen (MIT)</li>
<li><a href="http://www.stat.rice.edu/%7Egallen/stat640.html" rel="nofollow">Statistical Learning</a> - Genevera Allen (Rice University)</li>
<li><a href="http://www.cs.berkeley.edu/%7Ejordan/courses/294-fall09/" rel="nofollow">Practical Machine Learning</a> - Michael Jordan (UC Berkeley)</li>
<li><a href="http://videolectures.net/course_information_theory_pattern_recognition/" rel="nofollow">Course on Information Theory, Pattern Recognition, and Neural Networks</a> - David MacKay (University of Cambridge)</li>
<li><a href="http://web.stanford.edu/%7Elmackey/stats306b/" rel="nofollow">Methods for Applied Statistics: Unsupervised Learning</a> - Lester Mackey (Stanford)</li>
<li><a href="http://www.robots.ox.ac.uk/%7Eaz/lectures/ml/index.html" rel="nofollow">Machine Learning</a> - Andrew Zisserman (University of Oxford)</li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning--ud120" rel="nofollow">Intro to Machine Learning</a> - Sebastian Thrun (Stanford University)</li>
<li><a href="https://www.udacity.com/course/machine-learning--ud262" rel="nofollow">Machine Learning</a> - Charles Isbell, Michael Littman (Georgia Tech)</li>
<li><a href="https://cs231n.github.io/" rel="nofollow">(Convolutional) Neural Networks for Visual Recognition</a> - Fei-Fei Li, Andrej Karphaty, Justin Johnson (Stanford University)</li>
<li><a href="https://youtu.be/QZmZFeZxEKI?list=PLTBdjV_4f-EIiongKlS9OKrBEp8QR47Wl" rel="nofollow">Machine Learning for Computer Vision</a> - Rudolph Triebel (TU Munich)</li>
</ul>
<h4><a id="user-content-optimization" class="anchor" aria-hidden="true" href="#optimization"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Optimization</h4>
<ul>
<li><a href="http://stanford.edu/class/ee364a/" rel="nofollow">Convex Optimization I</a> - Stephen Boyd (Stanford University)</li>
<li><a href="http://stanford.edu/class/ee364b/" rel="nofollow">Convex Optimization II</a> - Stephen Boyd (Stanford University)</li>
<li><a href="https://class.stanford.edu/courses/Engineering/CVX101/Winter2014/about" rel="nofollow">Convex Optimization</a> - Stephen Boyd (Stanford University)</li>
<li><a href="http://optimization.mit.edu/classes.php" rel="nofollow">Optimization at MIT</a> - (MIT)</li>
<li><a href="http://www.stat.cmu.edu/%7Eryantibs/convexopt/" rel="nofollow">Convex Optimization</a> - Ryan Tibshirani (CMU)</li>
</ul>
<h2><a id="user-content-papers" class="anchor" aria-hidden="true" href="#papers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Papers</h2>
<h4><a id="user-content-conference-papers-on-the-web" class="anchor" aria-hidden="true" href="#conference-papers-on-the-web"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Conference papers on the web</h4>
<ul>
<li><a href="http://www.cvpapers.com/" rel="nofollow">CVPapers</a> - Computer vision papers on the web</li>
<li><a href="http://kesen.realtimerendering.com/" rel="nofollow">SIGGRAPH Paper on the web</a> - Graphics papers on the web</li>
<li><a href="http://papers.nips.cc/" rel="nofollow">NIPS Proceedings</a> - NIPS papers on the web</li>
<li><a href="http://www.cv-foundation.org/openaccess/menu.py" rel="nofollow">Computer Vision Foundation open access</a></li>
<li><a href="http://iris.usc.edu/Vision-Notes/bibliography/contents.html" rel="nofollow">Annotated Computer Vision Bibliography</a> - Keith Price (USC)</li>
<li><a href="http://iris.usc.edu/Information/Iris-Conferences.html" rel="nofollow">Calendar of Computer Image Analysis, Computer Vision Conferences</a> - (USC)</li>
</ul>
<h4><a id="user-content-survey-papers" class="anchor" aria-hidden="true" href="#survey-papers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Survey Papers</h4>
<ul>
<li><a href="http://surveys.visionbib.com/index.html" rel="nofollow">Visionbib Survey Paper List</a></li>
<li><a href="http://www.nowpublishers.com/CGV" rel="nofollow">Foundations and Trends® in Computer Graphics and Vision</a></li>
<li><a href="http://link.springer.com/book/10.1007/978-0-387-31439-6" rel="nofollow">Computer Vision: A Reference Guide</a></li>
</ul>
<h2><a id="user-content-tutorials-and-talks" class="anchor" aria-hidden="true" href="#tutorials-and-talks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Tutorials and talks</h2>
<h4><a id="user-content-computer-vision-2" class="anchor" aria-hidden="true" href="#computer-vision-2"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Computer Vision</h4>
<ul>
<li><a href="http://www.computervisiontalks.com/" rel="nofollow">Computer Vision Talks</a> - Lectures, keynotes, panel discussions on computer vision</li>
<li><a href="https://www.youtube.com/watch?v=Mqg6eorYRIQ" rel="nofollow">The Three R's of Computer Vision</a> - Jitendra Malik (UC Berkeley) 2013</li>
<li><a href="http://videolectures.net/epsrcws08_blake_amv/" rel="nofollow">Applications to Machine Vision</a> - Andrew Blake (Microsoft Research) 2008</li>
<li><a href="http://videolectures.net/kdd08_malik_fis/?q=image" rel="nofollow">The Future of Image Search</a> - Jitendra Malik (UC Berkeley) 2008</li>
<li><a href="https://www.youtube.com/watch?v=M17oGxh3Ny8" rel="nofollow">Should I do a PhD in Computer Vision?</a> - Fatih Porikli (Australian National University)</li>
</ul>
<ul>
<li><a href="http://www.ipam.ucla.edu/programs/summer-schools/graduate-summer-school-computer-vision/?tab=schedule" rel="nofollow">Graduate Summer School 2013: Computer Vision</a> - IPAM, 2013</li>
</ul>
<h4><a id="user-content-recent-conference-talks" class="anchor" aria-hidden="true" href="#recent-conference-talks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Recent Conference Talks</h4>
<ul>
<li><a href="http://www.pamitc.org/cvpr15/" rel="nofollow">CVPR 2015</a> - Jun 2015</li>
<li><a href="http://videolectures.net/eccv2014_zurich/" rel="nofollow">ECCV 2014</a> - Sep 2014</li>
<li><a href="http://techtalks.tv/cvpr-2014-oral-talks/" rel="nofollow">CVPR 2014</a> - Jun 2014</li>
<li><a href="http://techtalks.tv/iccv2013/" rel="nofollow">ICCV 2013</a> - Dec 2013</li>
<li><a href="http://techtalks.tv/icml/2013/" rel="nofollow">ICML 2013</a> - Jul 2013</li>
<li><a href="http://techtalks.tv/cvpr2013/" rel="nofollow">CVPR 2013</a> - Jun 2013</li>
<li><a href="http://videolectures.net/eccv2012_firenze/" rel="nofollow">ECCV 2012</a> - Oct 2012</li>
<li><a href="http://techtalks.tv/icml/2012/orals/" rel="nofollow">ICML 2012</a> - Jun 2012</li>
<li><a href="http://techtalks.tv/cvpr2012webcast/" rel="nofollow">CVPR 2012</a> - Jun 2012</li>
</ul>
<h4><a id="user-content-3d-computer-vision" class="anchor" aria-hidden="true" href="#3d-computer-vision"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>3D Computer Vision</h4>
<ul>
<li><a href="https://www.youtube.com/watch?v=kyIzMr917Rc" rel="nofollow">3D Computer Vision: Past, Present, and Future</a> - Steve Seitz (University of Washington) 2011</li>
<li><a href="https://www.youtube.com/watch?v=04Kgg3QEXFI" rel="nofollow">Reconstructing the World from Photos on the Internet</a> - Steve Seitz (University of Washington) 2013</li>
</ul>
<h4><a id="user-content-internet-vision" class="anchor" aria-hidden="true" href="#internet-vision"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Internet Vision</h4>
<ul>
<li><a href="http://www.technologyreview.com/video/426265/meet-2011-tr35-winner-noah-snavely/" rel="nofollow">The Distributed Camera</a> - Noah Snavely (Cornell University) 2011</li>
<li><a href="https://www.youtube.com/watch?v=UHkCa9-Z1Ps" rel="nofollow">Planet-Scale Visual Understanding</a> - Noah Snavely (Cornell University) 2014</li>
<li><a href="https://www.youtube.com/watch?v=6MWEfpKUfRc" rel="nofollow">A Trillion Photos</a> - Steve Seitz (University of Washington) 2013</li>
</ul>
<h4><a id="user-content-computational-photography-1" class="anchor" aria-hidden="true" href="#computational-photography-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Computational Photography</h4>
<ul>
<li><a href="https://www.youtube.com/watch?v=j90_0Ndk7XM" rel="nofollow">Reflections on Image-Based Modeling and Rendering</a> - Richard Szeliski (Microsoft Research) 2013</li>
<li><a href="https://www.youtube.com/watch?v=ZvPaHZZVPRk" rel="nofollow">Photographing Events over Time</a> - William T. Freeman (MIT) 2011</li>
<li><a href="http://videolectures.net/nipsworkshops2011_weiss_deconvolution/" rel="nofollow">Old and New algorithm for Blind Deconvolution</a> -  Yair Weiss (The Hebrew University of Jerusalem) 2011</li>
<li><a href="http://videolectures.net/nipsworkshops2010_milanfar_tmi/" rel="nofollow">A Tour of Modern "Image Processing"</a> -  Peyman Milanfar (UC Santa Cruz/Google) 2010</li>
<li><a href="http://videolectures.net/mlss07_blake_tiivp/" rel="nofollow">Topics in image and video processing</a> Andrew Blake (Microsoft Research) 2007</li>
<li><a href="https://www.youtube.com/watch?v=HJVNI0mkmqk" rel="nofollow">Computational Photography</a> - William T. Freeman (MIT) 2012</li>
<li><a href="https://www.youtube.com/watch?v=_BWnIQY_X98" rel="nofollow">Revealing the Invisible</a> - Frédo Durand (MIT) 2012</li>
<li><a href="https://www.youtube.com/watch?v=rE-hVtytT-I" rel="nofollow">Overview of Computer Vision and Visual Effects</a> - Rich Radke (Rensselaer Polytechnic Institute) 2014</li>
</ul>
<h4><a id="user-content-learning-and-vision" class="anchor" aria-hidden="true" href="#learning-and-vision"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Learning and Vision</h4>
<ul>
<li><a href="http://videolectures.net/colt2011_freeman_help/?q=computer%20vision" rel="nofollow">Where machine vision needs help from machine learning</a> - William T. Freeman (MIT) 2011</li>
<li><a href="http://videolectures.net/mlss08au_lucey_linv/" rel="nofollow">Learning in Computer Vision</a> - Simon Lucey (CMU) 2008</li>
<li><a href="http://videolectures.net/nips09_weiss_lil/?q=computer%20vision" rel="nofollow">Learning and Inference in Low-Level Vision</a> - Yair Weiss (The Hebrew University of Jerusalem) 2009</li>
</ul>
<h4><a id="user-content-object-recognition" class="anchor" aria-hidden="true" href="#object-recognition"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Object Recognition</h4>
<ul>
<li><a href="http://research.microsoft.com/apps/video/dl.aspx?id=231358" rel="nofollow">Object Recognition</a> - Larry Zitnick (Microsoft Research)</li>
<li><a href="http://videolectures.net/mlas06_li_gmvoo/?q=Fei-Fei%20Li" rel="nofollow">Generative Models for Visual Objects and Object Recognition via Bayesian Inference</a> - Fei-Fei Li (Stanford University)</li>
</ul>
<h4><a id="user-content-graphical-models" class="anchor" aria-hidden="true" href="#graphical-models"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Graphical Models</h4>
<ul>
<li><a href="http://videolectures.net/uai2012_felzenszwalb_computer_vision/?q=computer%20vision" rel="nofollow">Graphical Models for Computer Vision</a> - Pedro Felzenszwalb (Brown University) 2012</li>
<li><a href="http://videolectures.net/mlss09uk_ghahramani_gm/" rel="nofollow">Graphical Models</a> - Zoubin Ghahramani (University of Cambridge) 2009</li>
<li><a href="http://videolectures.net/mlss06tw_roweis_mlpgm/" rel="nofollow">Machine Learning, Probability and Graphical Models</a> - Sam Roweis (NYU) 2006</li>
<li><a href="http://videolectures.net/mlss09us_weiss_gma/?q=Graphical%20Models" rel="nofollow">Graphical Models and Applications</a> -  Yair Weiss (The Hebrew University of Jerusalem) 2009</li>
</ul>
<h4><a id="user-content-machine-learning-1" class="anchor" aria-hidden="true" href="#machine-learning-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Machine Learning</h4>
<ul>
<li><a href="https://nikola-rt.ee.washington.edu/people/bulyko/papers/em.pdf" rel="nofollow">A Gentle Tutorial of the EM Algorithm</a> - Jeff A. Bilmes (UC Berkeley) 1998</li>
<li><a href="http://videolectures.net/mlss09uk_bishop_ibi/" rel="nofollow">Introduction To Bayesian Inference</a> - Christopher Bishop (Microsoft Research) 2009</li>
<li><a href="http://videolectures.net/mlss06tw_lin_svm/" rel="nofollow">Support Vector Machines</a> - Chih-Jen Lin (National Taiwan University) 2006</li>
<li><a href="http://videolectures.net/mlss09uk_jordan_bfway/" rel="nofollow">Bayesian or Frequentist, Which Are You? </a> - Michael I. Jordan (UC Berkeley)</li>
</ul>
<h4><a id="user-content-optimization-1" class="anchor" aria-hidden="true" href="#optimization-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Optimization</h4>
<ul>
<li><a href="http://videolectures.net/nips2010_wright_oaml/" rel="nofollow">Optimization Algorithms in Machine Learning</a> - Stephen J. Wright (University of Wisconsin-Madison)</li>
<li><a href="http://videolectures.net/mlss07_vandenberghe_copt/?q=convex%20optimization" rel="nofollow">Convex Optimization</a> - Lieven Vandenberghe (University of California, Los Angeles)</li>
<li><a href="https://www.youtube.com/watch?v=oZqoWozVDVg" rel="nofollow">Continuous Optimization in Computer Vision</a> - Andrew Fitzgibbon (Microsoft Research)</li>
<li><a href="http://videolectures.net/sahd2014_bach_stochastic_gradient/" rel="nofollow">Beyond stochastic gradient descent for large-scale machine learning</a> - Francis Bach (INRIA)</li>
<li><a href="https://www.youtube.com/playlist?list=PLTBdjV_4f-EJ7A2iIH5L5ztqqrWYjP2RI" rel="nofollow">Variational Methods for Computer Vision</a> - Daniel Cremers (Technische Universität München) (<a href="https://www.youtube.com/watch?v=GgcbVPNd3SI" rel="nofollow">lecture 18 missing from playlist</a>)</li>
</ul>
<h4><a id="user-content-deep-learning" class="anchor" aria-hidden="true" href="#deep-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Deep Learning</h4>
<ul>
<li><a href="http://videolectures.net/jul09_hinton_deeplearn/" rel="nofollow">A tutorial on Deep Learning</a> - Geoffrey E. Hinton (University of Toronto)</li>
<li><a href="http://videolectures.net/kdd2014_salakhutdinov_deep_learning/?q=Hidden%20Markov%20model#" rel="nofollow">Deep Learning</a> -  Ruslan Salakhutdinov (University of Toronto)</li>
<li><a href="http://videolectures.net/kdd2014_bengio_deep_learning/" rel="nofollow">Scaling up Deep Learning</a> - Yoshua Bengio (University of Montreal)</li>
<li><a href="http://videolectures.net/machine_krizhevsky_imagenet_classification/?q=deep%20learning" rel="nofollow">ImageNet Classification with Deep Convolutional Neural Networks</a> -  Alex Krizhevsky (University of Toronto)</li>
<li><a href="http://videolectures.net/sahd2014_lecun_deep_learning/" rel="nofollow">The Unreasonable Effectivness Of Deep Learning</a> Yann LeCun (NYU/Facebook Research) 2014</li>
<li><a href="https://www.youtube.com/watch?v=qgx57X0fBdA" rel="nofollow">Deep Learning for Computer Vision</a> - Rob Fergus (NYU/Facebook Research)</li>
<li><a href="http://videolectures.net/sahd2014_mallat_dimensional_learning/" rel="nofollow">High-dimensional learning with deep network contractions</a> - Stéphane Mallat (Ecole Normale Superieure)</li>
<li><a href="http://www.ipam.ucla.edu/programs/summer-schools/graduate-summer-school-deep-learning-feature-learning/?tab=schedule" rel="nofollow">Graduate Summer School 2012: Deep Learning, Feature Learning</a> - IPAM, 2012</li>
<li><a href="http://www.fields.utoronto.ca/programs/scientific/14-15/bigdata/machine/" rel="nofollow">Workshop on Big Data and Statistical Machine Learning</a></li>
<li><a href="https://www.youtube.com/channel/UC3ywjSv5OsDiDAnOP8C1NiQ" rel="nofollow">Machine Learning Summer School</a> - Reykjavik, Iceland 2014
<ul>
<li><a href="https://www.youtube.com/watch?v=JuimBuvEWBg" rel="nofollow">Deep Learning Session 1</a> - Yoshua Bengio (Universtiy of Montreal)</li>
<li><a href="https://www.youtube.com/watch?v=Fl-W7_z3w3o" rel="nofollow">Deep Learning Session 2</a> - Yoshua Bengio (University of Montreal)</li>
<li><a href="https://www.youtube.com/watch?v=_cohR7LAgWA" rel="nofollow">Deep Learning Session 3</a> - Yoshua Bengio (University of Montreal)</li>
</ul>
</li>
</ul>
<h2><a id="user-content-software" class="anchor" aria-hidden="true" href="#software"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Software</h2>
<h4><a id="user-content-external-resource-links" class="anchor" aria-hidden="true" href="#external-resource-links"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>External Resource Links</h4>
<ul>
<li><a href="https://sites.google.com/site/jbhuang0604/resources/vision" rel="nofollow">Computer Vision Resources</a> - Jia-Bin Huang (UIUC)</li>
<li><a href="http://www.cvpapers.com/rr.html" rel="nofollow">Computer Vision Algorithm Implementations</a> - CVPapers</li>
<li><a href="http://www.csee.wvu.edu/%7Exinl/reproducible_research.html" rel="nofollow">Source Code Collection for Reproducible Research</a> - Xin Li (West Virginia University)</li>
<li><a href="http://www.cs.cmu.edu/afs/cs/project/cil/ftp/html/v-source.html" rel="nofollow">CMU Computer Vision Page</a></li>
</ul>
<h4><a id="user-content-general-purpose-computer-vision-library" class="anchor" aria-hidden="true" href="#general-purpose-computer-vision-library"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>General Purpose Computer Vision Library</h4>
<ul>
<li><a href="http://opencv.org/" rel="nofollow">Open CV</a></li>
<li><a href="http://kyamagu.github.io/mexopencv/" rel="nofollow">mexopencv</a></li>
<li><a href="http://simplecv.org/" rel="nofollow">SimpleCV</a></li>
<li><a href="https://github.com/jesolem/PCV">Open source Python module for computer vision</a></li>
<li><a href="https://github.com/liuliu/ccv">ccv: A Modern Computer Vision Library</a></li>
<li><a href="http://www.vlfeat.org/" rel="nofollow">VLFeat</a></li>
<li><a href="http://www.mathworks.com/products/computer-vision/" rel="nofollow">Matlab Computer Vision System Toolbox</a></li>
<li><a href="http://vision.ucsd.edu/%7Epdollar/toolbox/doc/index.html" rel="nofollow">Piotr's Computer Vision Matlab Toolbox</a></li>
<li><a href="http://pointclouds.org/" rel="nofollow">PCL: Point Cloud Library</a></li>
<li><a href="https://gitorious.org/imageutilities" rel="nofollow">ImageUtilities</a></li>
</ul>
<h4><a id="user-content-multiple-view-computer-vision" class="anchor" aria-hidden="true" href="#multiple-view-computer-vision"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multiple-view Computer Vision</h4>
<ul>
<li><a href="http://www.robots.ox.ac.uk/%7Evgg/hzbook/code/" rel="nofollow">MATLAB Functions for Multiple View Geometry</a></li>
<li><a href="http://staffhome.ecm.uwa.edu.au/%7E00011811/Research/MatlabFns/index.html" rel="nofollow">Peter Kovesi's Matlab Functions for Computer Vision and Image Analysis</a></li>
<li><a href="http://laurentkneip.github.io/opengv/" rel="nofollow">OpenGV </a> - geometric computer vision algorithms</li>
<li><a href="http://cmp.felk.cvut.cz/mini/" rel="nofollow">MinimalSolvers</a> - Minimal problems solver</li>
<li><a href="http://www.gcc.tu-darmstadt.de/home/proj/mve/" rel="nofollow">Multi-View Environment</a></li>
<li><a href="http://ccwu.me/vsfm/" rel="nofollow">Visual SFM</a></li>
<li><a href="http://www.cs.cornell.edu/%7Esnavely/bundler/" rel="nofollow">Bundler SFM</a></li>
<li><a href="http://imagine.enpc.fr/%7Emoulonp/openMVG/" rel="nofollow">openMVG: open Multiple View Geometry</a> - Multiple View Geometry; Structure from Motion library &amp; softwares</li>
<li><a href="http://www.di.ens.fr/pmvs/" rel="nofollow">Patch-based Multi-view Stereo V2</a></li>
<li><a href="http://www.di.ens.fr/cmvs/" rel="nofollow">Clustering Views for Multi-view Stereo</a></li>
<li><a href="http://www.gris.informatik.tu-darmstadt.de/projects/floating-scale-surface-recon/" rel="nofollow">Floating Scale Surface Reconstruction</a></li>
<li><a href="http://www.gcc.tu-darmstadt.de/home/proj/texrecon/" rel="nofollow">Large-Scale Texturing of 3D Reconstructions</a></li>
<li><a href="https://github.com/openMVG/awesome_3DReconstruction_list">Awesome 3D reconstruction list</a></li>
</ul>
<h4><a id="user-content-feature-detection-and-extraction" class="anchor" aria-hidden="true" href="#feature-detection-and-extraction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Feature Detection and Extraction</h4>
<ul>
<li><a href="http://www.vlfeat.org/" rel="nofollow">VLFeat</a></li>
<li><a href="http://www.cs.ubc.ca/%7Elowe/keypoints/" rel="nofollow">SIFT</a>
<ul>
<li>David G. Lowe, "Distinctive image features from scale-invariant keypoints," International Journal of Computer Vision, 60, 2 (2004), pp. 91-110.</li>
</ul>
</li>
<li><a href="http://www.robots.ox.ac.uk/%7Evedaldi/code/siftpp.html" rel="nofollow">SIFT++</a></li>
<li><a href="http://www.asl.ethz.ch/people/lestefan/personal/BRISK" rel="nofollow">BRISK</a>
<ul>
<li>Stefan Leutenegger, Margarita Chli and Roland Siegwart, "BRISK: Binary Robust Invariant Scalable Keypoints", ICCV 2011</li>
</ul>
</li>
<li><a href="http://www.vision.ee.ethz.ch/%7Esurf/" rel="nofollow">SURF</a>
<ul>
<li>Herbert Bay, Andreas Ess, Tinne Tuytelaars, Luc Van Gool, "SURF: Speeded Up Robust Features", Computer Vision and Image Understanding (CVIU), Vol. 110, No. 3, pp. 346--359, 2008</li>
</ul>
</li>
<li><a href="http://www.ivpe.com/freak.htm" rel="nofollow">FREAK</a>
<ul>
<li>A. Alahi, R. Ortiz, and P. Vandergheynst, "FREAK: Fast Retina Keypoint", CVPR 2012</li>
</ul>
</li>
<li><a href="http://www.robesafe.com/personal/pablo.alcantarilla/kaze.html" rel="nofollow">AKAZE</a>
<ul>
<li>Pablo F. Alcantarilla, Adrien Bartoli and Andrew J. Davison, "KAZE Features", ECCV 2012</li>
</ul>
</li>
<li><a href="https://github.com/nourani/LBP">Local Binary Patterns</a></li>
</ul>
<h4><a id="user-content-high-dynamic-range-imaging" class="anchor" aria-hidden="true" href="#high-dynamic-range-imaging"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>High Dynamic Range Imaging</h4>
<ul>
<li><a href="https://github.com/banterle/HDR_Toolbox">HDR_Toolbox</a></li>
</ul>
<h4><a id="user-content-semantic-segmentation" class="anchor" aria-hidden="true" href="#semantic-segmentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Semantic Segmentation</h4>
<ul>
<li><a href="http://www.it-caesar.com/list-of-contemporary-semantic-segmentation-datasets/" rel="nofollow">List of Semantic Segmentation algorithms</a></li>
</ul>
<h4><a id="user-content-low-level-vision" class="anchor" aria-hidden="true" href="#low-level-vision"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Low-level Vision</h4>
<h6><a id="user-content-stereo-vision" class="anchor" aria-hidden="true" href="#stereo-vision"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Stereo Vision</h6>
<ul>
<li><a href="http://vision.middlebury.edu/stereo/" rel="nofollow">Middlebury Stereo Vision</a></li>
<li><a href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=stero" rel="nofollow">The KITTI Vision Benchmark Suite</a></li>
<li><a href="http://www.cvlibs.net/software/libelas/" rel="nofollow">LIBELAS: Library for Efficient Large-scale Stereo Matching</a></li>
<li><a href="http://www.6d-vision.com/ground-truth-stixel-dataset" rel="nofollow">Ground Truth Stixel Dataset</a></li>
</ul>
<h6><a id="user-content-optical-flow" class="anchor" aria-hidden="true" href="#optical-flow"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Optical Flow</h6>
<ul>
<li><a href="http://vision.middlebury.edu/flow/" rel="nofollow">Middlebury Optical Flow Evaluation</a></li>
<li><a href="http://sintel.is.tue.mpg.de/" rel="nofollow">MPI-Sintel Optical Flow Dataset and Evaluation</a></li>
<li><a href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=flow" rel="nofollow">The KITTI Vision Benchmark Suite</a></li>
<li><a href="http://hci.iwr.uni-heidelberg.de/Benchmarks/document/Challenging_Data_for_Stereo_and_Optical_Flow/" rel="nofollow">HCI Challenge</a></li>
<li><a href="http://people.csail.mit.edu/celiu/OpticalFlow/" rel="nofollow">Coarse2Fine Optical Flow</a> - Ce Liu (MIT)</li>
<li><a href="http://cs.brown.edu/%7Edqsun/code/cvpr10_flow_code.zip" rel="nofollow">Secrets of Optical Flow Estimation and Their Principles</a></li>
<li><a href="http://people.csail.mit.edu/celiu/OpticalFlow/" rel="nofollow">C++/MatLab Optical Flow by C. Liu (based on Brox et al. and Bruhn et al.)</a></li>
<li><a href="http://www.ctim.es/research_works/parallel_robust_optical_flow/" rel="nofollow">Parallel Robust Optical Flow by Sánchez Pérez et al.</a></li>
</ul>
<h6><a id="user-content-image-denoising" class="anchor" aria-hidden="true" href="#image-denoising"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Denoising</h6>
<p>BM3D, KSVD,</p>
<h6><a id="user-content-super-resolution" class="anchor" aria-hidden="true" href="#super-resolution"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Super-resolution</h6>
<ul>
<li><a href="http://www.robots.ox.ac.uk/%7Evgg/software/SR/" rel="nofollow">Multi-frame image super-resolution</a>
<ul>
<li>Pickup, L. C. Machine Learning in Multi-frame Image Super-resolution, PhD thesis 2008</li>
</ul>
</li>
<li><a href="http://people.csail.mit.edu/billf/project%20pages/sresCode/Markov%20Random%20Fields%20for%20Super-Resolution.html" rel="nofollow">Markov Random Fields for Super-Resolution</a>
<ul>
<li>W. T Freeman and C. Liu. Markov Random Fields for Super-resolution and Texture Synthesis. In A. Blake, P. Kohli, and C. Rother, eds., Advances in Markov Random Fields for Vision and Image Processing, Chapter 10. MIT Press, 2011</li>
</ul>
</li>
<li><a href="https://people.mpi-inf.mpg.de/%7Ekkim/supres/supres.htm" rel="nofollow">Sparse regression and natural image prior</a>
<ul>
<li>K. I. Kim and Y. Kwon, "Single-image super-resolution using sparse regression and natural image prior", IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 32, no. 6, pp. 1127-1133, 2010.</li>
</ul>
</li>
<li><a href="http://www.cs.technion.ac.il/%7Eelad/Various/SingleImageSR_TIP14_Box.zip" rel="nofollow">Single-Image Super Resolution via a Statistical Model</a>
<ul>
<li>T. Peleg and M. Elad, A Statistical Prediction Model Based on Sparse Representations for Single Image Super-Resolution, IEEE Transactions on Image Processing, Vol. 23, No. 6, Pages 2569-2582, June 2014</li>
</ul>
</li>
<li><a href="http://www.cs.technion.ac.il/%7Eelad/Various/Single_Image_SR.zip" rel="nofollow">Sparse Coding for Super-Resolution</a>
<ul>
<li>R. Zeyde, M. Elad, and M. Protter On Single Image Scale-Up using Sparse-Representations, Curves &amp; Surfaces, Avignon-France, June 24-30, 2010 (appears also in Lecture-Notes-on-Computer-Science - LNCS).</li>
</ul>
</li>
<li><a href="http://www.ifp.illinois.edu/%7Ejyang29/ScSR.htm" rel="nofollow">Patch-wise Sparse Recovery</a>
<ul>
<li>Jianchao Yang, John Wright, Thomas Huang, and Yi Ma. Image super-resolution via sparse representation. IEEE Transactions on Image Processing (TIP), vol. 19, issue 11, 2010.</li>
</ul>
</li>
<li><a href="http://www.jdl.ac.cn/user/hchang/doc/code.rar" rel="nofollow">Neighbor embedding</a>
<ul>
<li>H. Chang, D.Y. Yeung, Y. Xiong. Super-resolution through neighbor embedding. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), vol.1, pp.275-282, Washington, DC, USA, 27 June - 2 July 2004.</li>
</ul>
</li>
<li><a href="https://sites.google.com/site/yuzhushome/single-image-super-resolution-using-deformable-patches" rel="nofollow">Deformable Patches</a>
<ul>
<li>Yu Zhu, Yanning Zhang and Alan Yuille, Single Image Super-resolution using Deformable Patches, CVPR 2014</li>
</ul>
</li>
<li><a href="http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html" rel="nofollow">SRCNN</a>
<ul>
<li>Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang, Learning a Deep Convolutional Network for Image Super-Resolution, in ECCV 2014</li>
</ul>
</li>
<li><a href="http://www.vision.ee.ethz.ch/%7Etimofter/ACCV2014_ID820_SUPPLEMENTARY/index.html" rel="nofollow">A+: Adjusted Anchored Neighborhood Regression</a>
<ul>
<li>R. Timofte, V. De Smet, and L. Van Gool. A+: Adjusted Anchored Neighborhood Regression for Fast Super-Resolution, ACCV 2014</li>
</ul>
</li>
<li><a href="https://sites.google.com/site/jbhuang0604/publications/struct_sr" rel="nofollow">Transformed Self-Exemplars</a>
<ul>
<li>Jia-Bin Huang, Abhishek Singh, and Narendra Ahuja, Single Image Super-Resolution using Transformed Self-Exemplars, IEEE Conference on Computer Vision and Pattern Recognition, 2015</li>
</ul>
</li>
</ul>
<h6><a id="user-content-image-deblurring" class="anchor" aria-hidden="true" href="#image-deblurring"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Deblurring</h6>
<p>Non-blind deconvolution</p>
<ul>
<li><a href="http://homes.cs.washington.edu/%7Eshanqi/work/spvdeconv/" rel="nofollow">Spatially variant non-blind deconvolution</a></li>
<li><a href="http://cg.postech.ac.kr/research/deconv_outliers/" rel="nofollow">Handling Outliers in Non-blind Image Deconvolution</a></li>
<li><a href="http://cs.nyu.edu/%7Edilip/research/fast-deconvolution/" rel="nofollow">Hyper-Laplacian Priors</a></li>
<li><a href="http://people.csail.mit.edu/danielzoran/epllcode.zip" rel="nofollow">From Learning Models of Natural Image Patches to Whole Image Restoration</a></li>
<li><a href="http://lxu.me/projects/dcnn/" rel="nofollow">Deep Convolutional Neural Network for Image Deconvolution</a></li>
<li><a href="http://webdav.is.mpg.de/pixel/neural_deconvolution/" rel="nofollow">Neural Deconvolution</a></li>
</ul>
<p>Blind deconvolution</p>
<ul>
<li><a href="http://www.cs.nyu.edu/%7Efergus/research/deblur.html" rel="nofollow">Removing Camera Shake From A Single Photograph</a></li>
<li><a href="http://www.cse.cuhk.edu.hk/leojia/projects/motion_deblurring/" rel="nofollow">High-quality motion deblurring from a single image</a></li>
<li><a href="http://www.cse.cuhk.edu.hk/leojia/projects/robust_deblur/" rel="nofollow">Two-Phase Kernel Estimation for Robust Motion Deblurring</a></li>
<li><a href="http://people.csail.mit.edu/taegsang/Documents/RadonDeblurringCode.zip" rel="nofollow">Blur kernel estimation using the radon transform</a></li>
<li><a href="http://cg.postech.ac.kr/research/fast_motion_deblurring/" rel="nofollow">Fast motion deblurring</a></li>
<li><a href="http://cs.nyu.edu//%7Edilip/research/blind-deconvolution/" rel="nofollow">Blind Deconvolution Using a Normalized Sparsity Measure</a></li>
<li><a href="http://www.cs.huji.ac.il/%7Eraananf/projects/deblur/" rel="nofollow">Blur-kernel estimation from spectral irregularities</a></li>
<li><a href="http://www.wisdom.weizmann.ac.il/%7Elevina/papers/LevinEtalCVPR2011Code.zip" rel="nofollow">Efficient marginal likelihood optimization in blind deconvolution</a></li>
<li><a href="http://www.cse.cuhk.edu.hk/leojia/projects/l0deblur/" rel="nofollow">Unnatural L0 Sparse Representation for Natural Image Deblurring</a></li>
<li><a href="http://cs.brown.edu/%7Elbsun/deblur2013/deblur2013iccp.html" rel="nofollow">Edge-based Blur Kernel Estimation Using Patch Priors</a></li>
<li><a href="http://www.wisdom.weizmann.ac.il/%7Evision/BlindDeblur.html" rel="nofollow">Blind Deblurring Using Internal Patch Recurrence</a></li>
</ul>
<p>Non-uniform Deblurring</p>
<ul>
<li><a href="http://www.di.ens.fr/willow/research/deblurring/" rel="nofollow">Non-uniform Deblurring for Shaken Images</a></li>
<li><a href="http://grail.cs.washington.edu/projects/mdf_deblurring/" rel="nofollow">Single Image Deblurring Using Motion Density Functions</a></li>
<li><a href="http://research.microsoft.com/en-us/um/redmond/groups/ivm/imudeblurring/" rel="nofollow">Image Deblurring using Inertial Measurement Sensors</a></li>
<li><a href="http://webdav.is.mpg.de/pixel/fast_removal_of_camera_shake/" rel="nofollow">Fast Removal of Non-uniform Camera Shake</a></li>
</ul>
<h6><a id="user-content-image-completion" class="anchor" aria-hidden="true" href="#image-completion"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Completion</h6>
<ul>
<li><a href="http://registry.gimp.org/node/27986" rel="nofollow">GIMP Resynthesizer</a></li>
<li><a href="http://lafarren.com/image-completer/" rel="nofollow">Priority BP</a></li>
<li><a href="http://www.ece.ucsb.edu/%7Epsen/melding" rel="nofollow">ImageMelding</a></li>
<li><a href="https://sites.google.com/site/jbhuang0604/publications/struct_completion" rel="nofollow">PlanarStructureCompletion</a></li>
</ul>
<h6><a id="user-content-image-retargeting" class="anchor" aria-hidden="true" href="#image-retargeting"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Retargeting</h6>
<ul>
<li><a href="http://people.csail.mit.edu/mrub/retargetme/" rel="nofollow">RetargetMe</a></li>
</ul>
<h6><a id="user-content-alpha-matting" class="anchor" aria-hidden="true" href="#alpha-matting"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Alpha Matting</h6>
<ul>
<li><a href="http://www.alphamatting.com/" rel="nofollow">Alpha Matting Evaluation</a></li>
<li><a href="http://people.csail.mit.edu/alevin/matting.tar.gz" rel="nofollow">Closed-form image matting</a></li>
<li><a href="http://www.vision.huji.ac.il/SpectralMatting/" rel="nofollow">Spectral Matting</a></li>
<li><a href="http://www.mathworks.com/matlabcentral/fileexchange/31412-learning-based-digital-matting" rel="nofollow">Learning-based Matting</a></li>
<li><a href="http://www.alphamatting.com/ImprovingMattingComprehensiveSamplingSets_CVPR2013.zip" rel="nofollow">Improving Image Matting using Comprehensive Sampling Sets</a></li>
</ul>
<h6><a id="user-content-image-pyramid" class="anchor" aria-hidden="true" href="#image-pyramid"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Pyramid</h6>
<ul>
<li><a href="http://www.cns.nyu.edu/%7Eeero/steerpyr/" rel="nofollow">The Steerable Pyramid</a></li>
<li><a href="http://www.curvelet.org/" rel="nofollow">CurveLab</a></li>
</ul>
<h6><a id="user-content-edge-preserving-image-processing" class="anchor" aria-hidden="true" href="#edge-preserving-image-processing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Edge-preserving image processing</h6>
<ul>
<li><a href="http://people.csail.mit.edu/sparis/bf/" rel="nofollow">Fast Bilateral Filter</a></li>
<li><a href="http://www.cs.cityu.edu.hk/%7Eqiyang/publications/code/qx.cvpr09.ctbf.zip" rel="nofollow">O(1) Bilateral Filter</a></li>
<li><a href="http://www.cs.cityu.edu.hk/%7Eqiyang/publications/eccv-12/" rel="nofollow">Recursive Bilateral Filtering</a></li>
<li><a href="http://www.cse.cuhk.edu.hk/leojia/projects/rollguidance/" rel="nofollow">Rolling Guidance Filter</a></li>
<li><a href="http://www.cse.cuhk.edu.hk/leojia/projects/texturesep/index.html" rel="nofollow">Relative Total Variation</a></li>
<li><a href="http://www.cse.cuhk.edu.hk/leojia/projects/L0smoothing/index.html" rel="nofollow">L0 Gradient Optimization</a></li>
<li><a href="http://www.inf.ufrgs.br/%7Eeslgastal/DomainTransform/" rel="nofollow">Domain Transform</a></li>
<li><a href="http://inf.ufrgs.br/%7Eeslgastal/AdaptiveManifolds/" rel="nofollow">Adaptive Manifold</a></li>
<li><a href="http://research.microsoft.com/en-us/um/people/kahe/eccv10/" rel="nofollow">Guided image filtering</a></li>
</ul>
<h4><a id="user-content-intrinsic-images" class="anchor" aria-hidden="true" href="#intrinsic-images"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Intrinsic Images</h4>
<ul>
<li><a href="http://people.tuebingen.mpg.de/mkiefel/projects/intrinsic/" rel="nofollow">Recovering Intrinsic Images with a global Sparsity Prior on Reflectance</a></li>
<li><a href="http://giga.cps.unizar.es/%7Eelenag/projects/EGSR2012_intrinsic/" rel="nofollow">Intrinsic Images by Clustering</a></li>
</ul>
<h4><a id="user-content-contour-detection-and-image-segmentation" class="anchor" aria-hidden="true" href="#contour-detection-and-image-segmentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Contour Detection and Image Segmentation</h4>
<ul>
<li><a href="http://coewww.rutgers.edu/riul/research/code/EDISON/" rel="nofollow">Mean Shift Segmentation</a></li>
<li><a href="http://cs.brown.edu/%7Epff/segment/" rel="nofollow">Graph-based Segmentation</a></li>
<li><a href="http://www.cis.upenn.edu/%7Ejshi/software/" rel="nofollow">Normalized Cut</a></li>
<li><a href="http://grabcut.weebly.com/background--algorithm.html" rel="nofollow">Grab Cut</a></li>
<li><a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html" rel="nofollow">Contour Detection and Image Segmentation</a></li>
<li><a href="http://research.microsoft.com/en-us/downloads/389109f6-b4e8-404c-84bf-239f7cbf4e3d/" rel="nofollow">Structured Edge Detection</a></li>
<li><a href="http://web.mit.edu/phillipi/pmi-boundaries/" rel="nofollow">Pointwise Mutual Information</a></li>
<li><a href="http://ivrl.epfl.ch/research/superpixels" rel="nofollow">SLIC Super-pixel</a></li>
<li><a href="http://www.vlfeat.org/overview/quickshift.html" rel="nofollow">QuickShift</a></li>
<li><a href="http://www.cs.toronto.edu/%7Ebabalex/research.html" rel="nofollow">TurboPixels</a></li>
<li><a href="http://mingyuliu.net/" rel="nofollow">Entropy Rate Superpixel</a></li>
<li><a href="http://www.vsi.cs.uni-frankfurt.de/research/current-projects/research/superpixel-segmentation/" rel="nofollow">Contour Relaxed Superpixels</a></li>
<li><a href="http://www.mvdblive.org/seeds/" rel="nofollow">SEEDS</a></li>
<li><a href="https://github.com/davidstutz/seeds-revised">SEEDS Revised</a></li>
<li><a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/" rel="nofollow">Multiscale Combinatorial Grouping</a></li>
<li><a href="https://github.com/pdollar/edges">Fast Edge Detection Using Structured Forests</a></li>
</ul>
<h4><a id="user-content-interactive-image-segmentation" class="anchor" aria-hidden="true" href="#interactive-image-segmentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Interactive Image Segmentation</h4>
<ul>
<li><a href="http://cns.bu.edu/%7Elgrady/software.html" rel="nofollow">Random Walker</a></li>
<li><a href="http://www.tc.umn.edu/%7Ebaixx015/" rel="nofollow">Geodesic Segmentation</a></li>
<li><a href="http://research.microsoft.com/apps/pubs/default.aspx?id=69040" rel="nofollow">Lazy Snapping</a></li>
<li><a href="http://powerwatershed.sourceforge.net/" rel="nofollow">Power Watershed</a></li>
<li><a href="http://www.adobe.com/technology/people/san-jose/brian-price.html" rel="nofollow">Geodesic Graph Cut</a></li>
<li><a href="http://www.cs.cmu.edu/%7Eolivierd/" rel="nofollow">Segmentation by Transduction</a></li>
</ul>
<h4><a id="user-content-video-segmentation" class="anchor" aria-hidden="true" href="#video-segmentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Video Segmentation</h4>
<ul>
<li><a href="http://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/image-and-video-segmentation/video-segmentation-with-superpixels/" rel="nofollow">Video Segmentation with Superpixels</a></li>
<li><a href="http://www.cc.gatech.edu/cpl/projects/videosegmentation/" rel="nofollow">Efficient hierarchical graph-based video segmentation</a></li>
<li><a href="http://lmb.informatik.uni-freiburg.de/Publications/2011/OB11/" rel="nofollow">Object segmentation in video</a></li>
<li><a href="http://www.cse.buffalo.edu/%7Ejcorso/r/supervoxels/" rel="nofollow">Streaming hierarchical video segmentation</a></li>
</ul>
<h4><a id="user-content-camera-calibration" class="anchor" aria-hidden="true" href="#camera-calibration"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Camera calibration</h4>
<ul>
<li><a href="http://www.vision.caltech.edu/bouguetj/calib_doc/" rel="nofollow">Camera Calibration Toolbox for Matlab</a></li>
<li><a href="http://docs.opencv.org/trunk/doc/tutorials/calib3d/camera_calibration/camera_calibration.html#" rel="nofollow">Camera calibration With OpenCV</a></li>
<li><a href="https://sites.google.com/site/prclibo/toolbox" rel="nofollow">Multiple Camera Calibration Toolbox</a></li>
</ul>
<h4><a id="user-content-simultaneous-localization-and-mapping" class="anchor" aria-hidden="true" href="#simultaneous-localization-and-mapping"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Simultaneous localization and mapping</h4>
<h6><a id="user-content-slam-community" class="anchor" aria-hidden="true" href="#slam-community"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>SLAM community:</h6>
<ul>
<li><a href="https://www.openslam.org/" rel="nofollow">openSLAM</a></li>
<li><a href="http://www.cvlibs.net/datasets/kitti/eval_odometry.php" rel="nofollow">Kitti Odometry: benchmark for outdoor visual odometry (codes may be available)</a></li>
</ul>
<h6><a id="user-content-trackingodometry" class="anchor" aria-hidden="true" href="#trackingodometry"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Tracking/Odometry:</h6>
<ul>
<li><a href="http://www.cvlibs.net/software/libviso/" rel="nofollow">LIBVISO2: C++ Library for Visual Odometry 2</a></li>
<li><a href="http://www.robots.ox.ac.uk/%7Egk/PTAM/" rel="nofollow">PTAM: Parallel tracking and mapping</a></li>
<li><a href="https://github.com/GerhardR/kfusion">KFusion: Implementation of KinectFusion</a></li>
<li><a href="https://github.com/Nerei/kinfu_remake">kinfu_remake: Lightweight, reworked and optimized version of Kinfu.</a></li>
<li><a href="http://las-vegas.uni-osnabrueck.de/related-projects/lvr-kinfu/" rel="nofollow">LVR-KinFu: kinfu_remake based Large Scale KinectFusion with online reconstruction</a></li>
<li><a href="http://www.robots.ox.ac.uk/%7Evictor/infinitam/" rel="nofollow">InfiniTAM: Implementation of multi-platform large-scale depth tracking and fusion</a></li>
<li><a href="https://github.com/nachtmar/VoxelHashing">VoxelHashing: Large-scale KinectFusion</a></li>
<li><a href="http://apt.cs.manchester.ac.uk/projects/PAMELA/tools/SLAMBench/" rel="nofollow">SLAMBench: Multiple-implementation of KinectFusion</a></li>
<li><a href="https://github.com/uzh-rpg/rpg_svo">SVO: Semi-direct visual odometry</a></li>
<li><a href="https://github.com/tum-vision/dvo_slam">DVO: dense visual odometry</a></li>
<li><a href="https://code.google.com/p/fovis/" rel="nofollow">FOVIS: RGB-D visual odometry</a></li>
</ul>
<h6><a id="user-content-graph-optimization" class="anchor" aria-hidden="true" href="#graph-optimization"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Graph Optimization:</h6>
<ul>
<li><a href="https://collab.cc.gatech.edu/borg/gtsam?destination=node%2F299" rel="nofollow">GTSAM: General smoothing and mapping library for Robotics and SFM</a> -- Georgia Institute of Technology</li>
<li><a href="https://github.com/RainerKuemmerle/g2o">G2O: General framework for graph optomization</a></li>
</ul>
<h6><a id="user-content-loop-closure" class="anchor" aria-hidden="true" href="#loop-closure"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Loop Closure:</h6>
<ul>
<li><a href="http://www.robots.ox.ac.uk/%7Emjc/Software.htm" rel="nofollow">FabMap: appearance-based loop closure system</a> - also available in <a href="http://docs.opencv.org/2.4/modules/contrib/doc/openfabmap.html" rel="nofollow">OpenCV2.4.11</a></li>
<li><a href="http://webdiis.unizar.es/%7Edorian/index.php?p=32" rel="nofollow">DBoW2: binary bag-of-words loop detection system</a></li>
</ul>
<h6><a id="user-content-localization--mapping" class="anchor" aria-hidden="true" href="#localization--mapping"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Localization &amp; Mapping:</h6>
<ul>
<li><a href="https://code.google.com/p/ratslam/" rel="nofollow">RatSLAM</a></li>
<li><a href="https://github.com/tum-vision/lsd_slam">LSD-SLAM</a></li>
<li><a href="https://github.com/raulmur/ORB_SLAM">ORB-SLAM</a></li>
</ul>
<h4><a id="user-content-single-view-spatial-understanding" class="anchor" aria-hidden="true" href="#single-view-spatial-understanding"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Single-view Spatial Understanding</h4>
<ul>
<li><a href="http://web.engr.illinois.edu/%7Edhoiem/projects/software.html" rel="nofollow">Geometric Context</a> - Derek Hoiem (CMU)</li>
<li><a href="http://web.engr.illinois.edu/%7Edhoiem/software/counter.php?Down=varsha_spatialLayout.zip" rel="nofollow">Recovering Spatial Layout</a> - Varsha Hedau (UIUC)</li>
<li><a href="http://www.cs.cmu.edu/%7E./dclee/code/index.html" rel="nofollow">Geometric Reasoning</a> - David C. Lee (CMU)</li>
<li><a href="https://github.com/arron2003/rgbd2full3d">RGBD2Full3D</a> - Ruiqi Guo (UIUC)</li>
</ul>
<h4><a id="user-content-object-detection" class="anchor" aria-hidden="true" href="#object-detection"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Object Detection</h4>
<ul>
<li><a href="http://pascal.inrialpes.fr/soft/olt/" rel="nofollow">INRIA Object Detection and Localization Toolkit</a></li>
<li><a href="http://www.cs.berkeley.edu/%7Erbg/latent/" rel="nofollow">Discriminatively trained deformable part models</a></li>
<li><a href="https://github.com/rbgirshick/voc-dpm">VOC-DPM</a></li>
<li><a href="http://www.ics.uci.edu/%7Edramanan/software/sparse/" rel="nofollow">Histograms of Sparse Codes for Object Detection</a></li>
<li><a href="https://github.com/rbgirshick/rcnn">R-CNN: Regions with Convolutional Neural Network Features</a></li>
<li><a href="https://github.com/ShaoqingRen/SPP_net">SPP-Net</a></li>
<li><a href="http://mmcheng.net/bing/comment-page-9/" rel="nofollow">BING: Objectness Estimation</a></li>
<li><a href="https://github.com/pdollar/edges">Edge Boxes</a></li>
<li><a href="https://github.com/Russell91/ReInspect">ReInspect</a></li>
</ul>
<h4><a id="user-content-nearest-neighbor-search" class="anchor" aria-hidden="true" href="#nearest-neighbor-search"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Nearest Neighbor Search</h4>
<h6><a id="user-content-general-purpose-nearest-neighbor-search" class="anchor" aria-hidden="true" href="#general-purpose-nearest-neighbor-search"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>General purpose nearest neighbor search</h6>
<ul>
<li><a href="http://www.cs.umd.edu/%7Emount/ANN/" rel="nofollow">ANN: A Library for Approximate Nearest Neighbor Searching</a></li>
<li><a href="http://www.cs.ubc.ca/research/flann/" rel="nofollow">FLANN - Fast Library for Approximate Nearest Neighbors</a></li>
<li><a href="http://vincentfpgarcia.github.io/kNN-CUDA/" rel="nofollow">Fast k nearest neighbor search using GPU</a></li>
</ul>
<h6><a id="user-content-nearest-neighbor-field-estimation" class="anchor" aria-hidden="true" href="#nearest-neighbor-field-estimation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Nearest Neighbor Field Estimation</h6>
<ul>
<li><a href="http://gfx.cs.princeton.edu/gfx/pubs/Barnes_2009_PAR/index.php" rel="nofollow">PatchMatch</a></li>
<li><a href="http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/index.php" rel="nofollow">Generalized PatchMatch</a></li>
<li><a href="http://www.eng.tau.ac.il/%7Esimonk/CSH/" rel="nofollow">Coherency Sensitive Hashing</a></li>
<li><a href="https://github.com/fbesse/pmbp">PMBP: PatchMatch Belief Propagation</a></li>
<li><a href="http://www.eng.tau.ac.il/%7Eavidan/papers/TreeCANN_code_20121022.rar" rel="nofollow">TreeCANN</a></li>
</ul>
<h4><a id="user-content-visual-tracking" class="anchor" aria-hidden="true" href="#visual-tracking"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Visual Tracking</h4>
<ul>
<li><a href="https://sites.google.com/site/trackerbenchmark/benchmarks/v10" rel="nofollow">Visual Tracker Benchmark</a></li>
<li><a href="http://www.votchallenge.net/" rel="nofollow">Visual Tracking Challenge</a></li>
<li><a href="http://www.ces.clemson.edu/%7Estb/klt/" rel="nofollow">Kanade-Lucas-Tomasi Feature Tracker</a></li>
<li><a href="http://www.eng.tau.ac.il/%7Eoron/ELK/ELK.html" rel="nofollow">Extended Lucas-Kanade Tracking</a></li>
<li><a href="http://www.vision.ee.ethz.ch/boostingTrackers/" rel="nofollow">Online-boosting Tracking</a></li>
<li><a href="http://www4.comp.polyu.edu.hk/%7Ecslzhang/STC/STC.htm" rel="nofollow">Spatio-Temporal Context Learning</a></li>
<li><a href="http://www.shengfenghe.com/visual-tracking-via-locality-sensitive-histograms.html" rel="nofollow">Locality Sensitive Histograms</a></li>
<li><a href="http://www.cv-foundation.org/openaccess/content_iccv_workshops_2013/W03/papers/Xiao_An_Enhanced_Adaptive_2013_ICCV_paper.pdf" rel="nofollow">Enhanced adaptive coupled-layer LGTracker++</a></li>
<li><a href="http://personal.ee.surrey.ac.uk/Personal/Z.Kalal/tld.html" rel="nofollow">TLD: Tracking - Learning - Detection</a></li>
<li><a href="http://www.gnebehay.com/cmt/" rel="nofollow">CMT: Clustering of Static-Adaptive Correspondences for Deformable Object Tracking</a></li>
<li><a href="http://home.isr.uc.pt/%7Ehenriques/circulant/" rel="nofollow">Kernelized Correlation Filters</a></li>
<li><a href="http://www.cvl.isy.liu.se/en/research/objrec/visualtracking/scalvistrack/index.html" rel="nofollow">Accurate Scale Estimation for Robust Visual Tracking</a></li>
<li><a href="http://cs-people.bu.edu/jmzhang/MEEM/MEEM.html" rel="nofollow">Multiple Experts using Entropy Minimization</a></li>
<li><a href="http://www.dabi.temple.edu/%7Ehbling/code/TGPR.htm" rel="nofollow">TGPR</a></li>
<li><a href="https://sites.google.com/site/jbhuang0604/publications/cf2" rel="nofollow">CF2: Hierarchical Convolutional Features for Visual Tracking</a></li>
<li><a href="http://webdocs.cs.ualberta.ca/%7Evis/mtf/index.html" rel="nofollow">Modular Tracking Framework</a></li>
</ul>
<h4><a id="user-content-saliency-detection" class="anchor" aria-hidden="true" href="#saliency-detection"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Saliency Detection</h4>
<h4><a id="user-content-attributes" class="anchor" aria-hidden="true" href="#attributes"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Attributes</h4>
<h4><a id="user-content-action-reconition" class="anchor" aria-hidden="true" href="#action-reconition"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Action Reconition</h4>
<h4><a id="user-content-egocentric-cameras" class="anchor" aria-hidden="true" href="#egocentric-cameras"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Egocentric cameras</h4>
<h4><a id="user-content-human-in-the-loop-systems" class="anchor" aria-hidden="true" href="#human-in-the-loop-systems"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Human-in-the-loop systems</h4>
<h4><a id="user-content-image-captioning" class="anchor" aria-hidden="true" href="#image-captioning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Captioning</h4>
<ul>
<li><a href="https://github.com/karpathy/neuraltalk%EF%BB%BF">NeuralTalk</a> -</li>
</ul>
<h4><a id="user-content-optimization-2" class="anchor" aria-hidden="true" href="#optimization-2"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Optimization</h4>
<ul>
<li><a href="http://ceres-solver.org/" rel="nofollow">Ceres Solver</a> - Nonlinear least-square problem and unconstrained optimization solver</li>
<li><a href="http://ab-initio.mit.edu/wiki/index.php/NLopt" rel="nofollow">NLopt</a>- Nonlinear least-square problem and unconstrained optimization solver</li>
<li><a href="http://hci.iwr.uni-heidelberg.de/opengm2/" rel="nofollow">OpenGM</a> - Factor graph based discrete optimization and inference solver</li>
<li><a href="https://collab.cc.gatech.edu/borg/gtsam/" rel="nofollow">GTSAM</a> - Factor graph based lease-square optimization solver</li>
</ul>
<h4><a id="user-content-deep-learning-1" class="anchor" aria-hidden="true" href="#deep-learning-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Deep Learning</h4>
<ul>
<li><a href="https://github.com/kjw0612/awesome-deep-vision">Awesome Deep Vision</a></li>
</ul>
<h4><a id="user-content-machine-learning-2" class="anchor" aria-hidden="true" href="#machine-learning-2"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Machine Learning</h4>
<ul>
<li><a href="https://github.com/josephmisiti/awesome-machine-learning">Awesome Machine Learning</a></li>
<li><a href="http://idiap.github.io/bob/" rel="nofollow">Bob: a free signal processing and machine learning toolbox for researchers</a></li>
<li><a href="https://www.csie.ntu.edu.tw/%7Ecjlin/libsvm/" rel="nofollow">LIBSVM -- A Library for Support Vector Machines</a></li>
</ul>
<h2><a id="user-content-datasets" class="anchor" aria-hidden="true" href="#datasets"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Datasets</h2>
<h4><a id="user-content-external-dataset-link-collection" class="anchor" aria-hidden="true" href="#external-dataset-link-collection"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>External Dataset Link Collection</h4>
<ul>
<li><a href="http://www.cvpapers.com/datasets.html" rel="nofollow">CV Datasets on the web</a> - CVPapers</li>
<li><a href="http://rodrigob.github.io/are_we_there_yet/build/" rel="nofollow">Are we there yet?</a> - Which paper provides the best results on standard dataset X?</li>
<li><a href="http://www.cvpapers.com/datasets.html" rel="nofollow">Computer Vision Dataset on the web</a></li>
<li><a href="http://riemenschneider.hayko.at/vision/dataset/" rel="nofollow">Yet Another Computer Vision Index To Datasets</a></li>
<li><a href="http://www.computervisiononline.com/datasets" rel="nofollow">ComputerVisionOnline Datasets</a></li>
<li><a href="http://homepages.inf.ed.ac.uk/cgi/rbf/CVONLINE/entries.pl?TAG363" rel="nofollow">CVOnline Dataset</a></li>
<li><a href="http://clickdamage.com/sourcecode/cv_datasets.php" rel="nofollow">CV datasets</a></li>
<li><a href="http://datasets.visionbib.com/info-index.html" rel="nofollow">visionbib</a></li>
<li><a href="http://www.visualdata.io/" rel="nofollow">VisualData</a></li>
</ul>
<h4><a id="user-content-low-level-vision-1" class="anchor" aria-hidden="true" href="#low-level-vision-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Low-level Vision</h4>
<h6><a id="user-content-stereo-vision-1" class="anchor" aria-hidden="true" href="#stereo-vision-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Stereo Vision</h6>
<ul>
<li><a href="http://vision.middlebury.edu/stereo/" rel="nofollow">Middlebury Stereo Vision</a></li>
<li><a href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=stero" rel="nofollow">The KITTI Vision Benchmark Suite</a></li>
<li><a href="http://www.cvlibs.net/software/libelas/" rel="nofollow">LIBELAS: Library for Efficient Large-scale Stereo Matching</a></li>
<li><a href="http://www.6d-vision.com/ground-truth-stixel-dataset" rel="nofollow">Ground Truth Stixel Dataset</a></li>
</ul>
<h6><a id="user-content-optical-flow-1" class="anchor" aria-hidden="true" href="#optical-flow-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Optical Flow</h6>
<ul>
<li><a href="http://vision.middlebury.edu/flow/" rel="nofollow">Middlebury Optical Flow Evaluation</a></li>
<li><a href="http://sintel.is.tue.mpg.de/" rel="nofollow">MPI-Sintel Optical Flow Dataset and Evaluation</a></li>
<li><a href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=flow" rel="nofollow">The KITTI Vision Benchmark Suite</a></li>
<li><a href="http://hci.iwr.uni-heidelberg.de/Benchmarks/document/Challenging_Data_for_Stereo_and_Optical_Flow/" rel="nofollow">HCI Challenge</a></li>
</ul>
<h6><a id="user-content-video-object-segmentation" class="anchor" aria-hidden="true" href="#video-object-segmentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Video Object Segmentation</h6>
<ul>
<li><a href="http://davischallenge.org/" rel="nofollow">DAVIS: Densely Annotated VIdeo Segmentation</a></li>
<li><a href="http://web.engr.oregonstate.edu/%7Elif/SegTrack2/dataset.html" rel="nofollow">SegTrack v2</a></li>
</ul>
<h6><a id="user-content-change-detection" class="anchor" aria-hidden="true" href="#change-detection"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Change Detection</h6>
<ul>
<li><a href="http://www.gti.ssr.upm.es/data/LASIESTA" rel="nofollow">Labeled and Annotated Sequences for Integral Evaluation of SegmenTation Algorithms</a></li>
<li><a href="http://www.changedetection.net/" rel="nofollow">ChangeDetection.net</a></li>
</ul>
<h6><a id="user-content-image-super-resolutions" class="anchor" aria-hidden="true" href="#image-super-resolutions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Super-resolutions</h6>
<ul>
<li><a href="https://eng.ucmerced.edu/people/cyang35/ECCV14/ECCV14.html" rel="nofollow">Single-Image Super-Resolution: A Benchmark</a></li>
</ul>
<h4><a id="user-content-intrinsic-images-1" class="anchor" aria-hidden="true" href="#intrinsic-images-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Intrinsic Images</h4>
<ul>
<li><a href="http://www.mit.edu/%7Ekimo/publications/intrinsic/" rel="nofollow">Ground-truth dataset and baseline evaluations for intrinsic image algorithms</a></li>
<li><a href="http://opensurfaces.cs.cornell.edu/intrinsic/" rel="nofollow">Intrinsic Images in the Wild</a></li>
<li><a href="http://www.cic.uab.cat/Datasets/synthetic_intrinsic_image_dataset/" rel="nofollow">Intrinsic Image Evaluation on Synthetic Complex Scenes</a></li>
</ul>
<h4><a id="user-content-material-recognition" class="anchor" aria-hidden="true" href="#material-recognition"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Material Recognition</h4>
<ul>
<li><a href="http://opensurfaces.cs.cornell.edu/" rel="nofollow">OpenSurface</a></li>
<li><a href="http://people.csail.mit.edu/celiu/CVPR2010/" rel="nofollow">Flickr Material Database</a></li>
<li><a href="http://opensurfaces.cs.cornell.edu/publications/minc/" rel="nofollow">Materials in Context Dataset</a></li>
</ul>
<h4><a id="user-content-multi-view-reconsturction" class="anchor" aria-hidden="true" href="#multi-view-reconsturction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multi-view Reconsturction</h4>
<ul>
<li><a href="http://vision.middlebury.edu/mview/" rel="nofollow">Multi-View Stereo Reconstruction</a></li>
</ul>
<h4><a id="user-content-saliency-detection-1" class="anchor" aria-hidden="true" href="#saliency-detection-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Saliency Detection</h4>
<h4><a id="user-content-visual-tracking-1" class="anchor" aria-hidden="true" href="#visual-tracking-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Visual Tracking</h4>
<ul>
<li><a href="https://sites.google.com/site/trackerbenchmark/benchmarks/v10" rel="nofollow">Visual Tracker Benchmark</a></li>
<li><a href="https://sites.google.com/site/benchmarkpami/" rel="nofollow">Visual Tracker Benchmark v1.1</a></li>
<li><a href="http://www.votchallenge.net/" rel="nofollow">VOT Challenge</a></li>
<li><a href="http://tracking.cs.princeton.edu/" rel="nofollow">Princeton Tracking Benchmark</a></li>
<li><a href="http://webdocs.cs.ualberta.ca/%7Evis/trackDB/" rel="nofollow">Tracking Manipulation Tasks (TMT)</a></li>
</ul>
<h4><a id="user-content-visual-surveillance" class="anchor" aria-hidden="true" href="#visual-surveillance"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Visual Surveillance</h4>
<ul>
<li><a href="http://www.viratdata.org/" rel="nofollow">VIRAT</a></li>
<li><a href="https://cam2.ecn.purdue.edu/" rel="nofollow">CAM2</a></li>
</ul>
<h4><a id="user-content-saliency-detection-2" class="anchor" aria-hidden="true" href="#saliency-detection-2"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Saliency Detection</h4>
<h4><a id="user-content-change-detection-1" class="anchor" aria-hidden="true" href="#change-detection-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Change detection</h4>
<ul>
<li><a href="http://changedetection.net/" rel="nofollow">ChangeDetection.net</a></li>
</ul>
<h4><a id="user-content-visual-recognition" class="anchor" aria-hidden="true" href="#visual-recognition"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Visual Recognition</h4>
<h6><a id="user-content-image-classification" class="anchor" aria-hidden="true" href="#image-classification"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Classification</h6>
<ul>
<li><a href="http://pascallin.ecs.soton.ac.uk/challenges/VOC/" rel="nofollow">The PASCAL Visual Object Classes</a></li>
<li><a href="http://www.image-net.org/challenges/LSVRC/2014/" rel="nofollow">ImageNet Large Scale Visual Recognition Challenge</a></li>
</ul>
<h6><a id="user-content-scene-recognition" class="anchor" aria-hidden="true" href="#scene-recognition"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Scene Recognition</h6>
<ul>
<li><a href="http://groups.csail.mit.edu/vision/SUN/" rel="nofollow">SUN Database</a></li>
<li><a href="http://places.csail.mit.edu/" rel="nofollow">Place Dataset</a></li>
</ul>
<h6><a id="user-content-object-detection-1" class="anchor" aria-hidden="true" href="#object-detection-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Object Detection</h6>
<ul>
<li><a href="http://pascallin.ecs.soton.ac.uk/challenges/VOC/" rel="nofollow">The PASCAL Visual Object Classes</a></li>
<li><a href="http://www.image-net.org/challenges/LSVRC/2014/" rel="nofollow">ImageNet Object Detection Challenge</a></li>
<li><a href="http://mscoco.org/" rel="nofollow">Microsoft COCO</a></li>
</ul>
<h6><a id="user-content-semantic-labeling" class="anchor" aria-hidden="true" href="#semantic-labeling"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Semantic labeling</h6>
<ul>
<li><a href="http://dags.stanford.edu/projects/scenedataset.html" rel="nofollow">Stanford background dataset</a></li>
<li><a href="http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/" rel="nofollow">CamVid</a></li>
<li><a href="http://www.cs.unc.edu/%7Ejtighe/Papers/ECCV10/" rel="nofollow">Barcelona Dataset</a></li>
<li><a href="http://www.cs.unc.edu/%7Ejtighe/Papers/ECCV10/siftflow/SiftFlowDataset.zip" rel="nofollow">SIFT Flow Dataset</a></li>
</ul>
<h6><a id="user-content-multi-view-object-detection" class="anchor" aria-hidden="true" href="#multi-view-object-detection"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multi-view Object Detection</h6>
<ul>
<li><a href="http://cvgl.stanford.edu/resources.html" rel="nofollow">3D Object Dataset</a></li>
<li><a href="http://cvlab.epfl.ch/data/pose" rel="nofollow">EPFL Car Dataset</a></li>
<li><a href="http://www.cvlibs.net/datasets/kitti/eval_object.php" rel="nofollow">KTTI Dection Dataset</a></li>
<li><a href="http://sun3d.cs.princeton.edu/" rel="nofollow">SUN 3D Dataset</a></li>
<li><a href="http://cvgl.stanford.edu/projects/pascal3d.html" rel="nofollow">PASCAL 3D+</a></li>
<li><a href="http://nyc3d.cs.cornell.edu/" rel="nofollow">NYU Car Dataset</a></li>
</ul>
<h6><a id="user-content-fine-grained-visual-recognition" class="anchor" aria-hidden="true" href="#fine-grained-visual-recognition"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fine-grained Visual Recognition</h6>
<ul>
<li><a href="https://sites.google.com/site/fgcomp2013/" rel="nofollow">Fine-grained Classification Challenge</a></li>
<li><a href="http://www.vision.caltech.edu/visipedia/CUB-200.html" rel="nofollow">Caltech-UCSD Birds 200</a></li>
</ul>
<h6><a id="user-content-pedestrian-detection" class="anchor" aria-hidden="true" href="#pedestrian-detection"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Pedestrian Detection</h6>
<ul>
<li><a href="http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/" rel="nofollow">Caltech Pedestrian Detection Benchmark</a></li>
<li><a href="https://data.vision.ee.ethz.ch/cvl/aess/dataset/" rel="nofollow">ETHZ Pedestrian Detection</a></li>
</ul>
<h4><a id="user-content-action-recognition" class="anchor" aria-hidden="true" href="#action-recognition"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Action Recognition</h4>
<h6><a id="user-content-image-based" class="anchor" aria-hidden="true" href="#image-based"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image-based</h6>
<h6><a id="user-content-video-based" class="anchor" aria-hidden="true" href="#video-based"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Video-based</h6>
<ul>
<li><a href="http://www.di.ens.fr/%7Elaptev/actions/hollywood2/" rel="nofollow">HOLLYWOOD2 Dataset</a></li>
<li><a href="http://crcv.ucf.edu/data/UCF_Sports_Action.php" rel="nofollow">UCF Sports Action Data Set</a></li>
</ul>
<h6><a id="user-content-image-deblurring-1" class="anchor" aria-hidden="true" href="#image-deblurring-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Deblurring</h6>
<ul>
<li><a href="http://cs.brown.edu/%7Elbsun/deblur2013/deblur2013iccp.html" rel="nofollow">Sun dataset</a></li>
<li><a href="http://www.wisdom.weizmann.ac.il/%7Elevina/papers/LevinEtalCVPR09Data.rar" rel="nofollow">Levin dataset</a></li>
</ul>
<h4><a id="user-content-image-captioning-1" class="anchor" aria-hidden="true" href="#image-captioning-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Captioning</h4>
<ul>
<li><a href="http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/KCCA.html" rel="nofollow">Flickr 8K</a></li>
<li><a href="http://shannon.cs.illinois.edu/DenotationGraph/" rel="nofollow">Flickr 30K</a></li>
<li><a href="http://mscoco.org/" rel="nofollow">Microsoft COCO</a></li>
</ul>
<h4><a id="user-content-scene-understanding" class="anchor" aria-hidden="true" href="#scene-understanding"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Scene Understanding</h4>
<h1><a id="user-content-sun-rgb-d---a-rgb-d-scene-understanding-benchmark-suite" class="anchor" aria-hidden="true" href="#sun-rgb-d---a-rgb-d-scene-understanding-benchmark-suite"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="http://rgbd.cs.princeton.edu/" rel="nofollow">SUN RGB-D</a> - A RGB-D Scene Understanding Benchmark Suite</h1>
<h1><a id="user-content-nyu-depth-v2---indoor-segmentation-and-support-inference-from-rgbd-images" class="anchor" aria-hidden="true" href="#nyu-depth-v2---indoor-segmentation-and-support-inference-from-rgbd-images"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="http://cs.nyu.edu/%7Esilberman/datasets/nyu_depth_v2.html" rel="nofollow">NYU depth v2</a> - Indoor Segmentation and Support Inference from RGBD Images</h1>
<h4><a id="user-content-aerial-images" class="anchor" aria-hidden="true" href="#aerial-images"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Aerial images</h4>
<h1><a id="user-content-aerial-image-segmentation---learning-aerial-image-segmentation-from-online-maps" class="anchor" aria-hidden="true" href="#aerial-image-segmentation---learning-aerial-image-segmentation-from-online-maps"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://zenodo.org/record/1154821#.WmN9kHWnHIp" rel="nofollow">Aerial Image Segmentation</a> - Learning Aerial Image Segmentation From Online Maps</h1>
<h2><a id="user-content-resources-for-students" class="anchor" aria-hidden="true" href="#resources-for-students"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Resources for students</h2>
<h4><a id="user-content-resource-link-collection" class="anchor" aria-hidden="true" href="#resource-link-collection"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Resource link collection</h4>
<ul>
<li><a href="http://people.csail.mit.edu/fredo/student.html" rel="nofollow">Resources for students</a> - Frédo Durand (MIT)</li>
<li><a href="http://www.dgp.toronto.edu/%7Ehertzman/advice/" rel="nofollow">Advice for Graduate Students</a> - Aaron Hertzmann (Adobe Research)</li>
<li><a href="http://www.dgp.toronto.edu/%7Ehertzman/courses/gradSkills/2010/" rel="nofollow">Graduate Skills Seminars</a> - Yashar Ganjali, Aaron Hertzmann (University of Toronto)</li>
<li><a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/giving-a-talk/giving-a-talk.htm" rel="nofollow">Research Skills</a> - Simon Peyton Jones (Microsoft Research)</li>
<li><a href="http://web.engr.illinois.edu/%7Etaoxie/advice.htm" rel="nofollow">Resource collection</a> - Tao Xie (UIUC) and Yuan Xie (UCSB)</li>
</ul>
<h4><a id="user-content-writing" class="anchor" aria-hidden="true" href="#writing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Writing</h4>
<ul>
<li><a href="http://people.csail.mit.edu/fredo/FredoGoodWriting.pdf" rel="nofollow">Write Good Papers</a> - Frédo Durand (MIT)</li>
<li><a href="http://people.csail.mit.edu/fredo/PUBLI/writing.pdf" rel="nofollow">Notes on writing</a> - Frédo Durand (MIT)</li>
<li><a href="http://people.csail.mit.edu/fredo/FredoBadWriting.pdf" rel="nofollow">How to Write a Bad Article</a> - Frédo Durand (MIT)</li>
<li><a href="http://billf.mit.edu/sites/default/files/documents/cvprPapers.pdf" rel="nofollow">How to write a good CVPR submission</a> - William T. Freeman (MIT)</li>
<li><a href="https://www.youtube.com/watch?v=g3dkRsTqdDA" rel="nofollow">How to write a great research paper</a> - Simon Peyton Jones (Microsoft Research)</li>
<li><a href="http://www.slideshare.net/jdily/how-to-write-a-siggraph-paper" rel="nofollow">How to write a SIGGRAPH paper</a> - SIGGRAPH ASIA 2011 Course</li>
<li><a href="http://www.dgp.toronto.edu/%7Ehertzman/advice/writing-technical-papers.pdf" rel="nofollow">Writing Research Papers</a> - Aaron Hertzmann (Adobe Research)</li>
<li><a href="http://www.computer.org/csdl/mags/cg/1987/12/mcg1987120062.pdf" rel="nofollow">How to Write a Paper for SIGGRAPH</a> - Jim Blinn</li>
<li><a href="http://www.siggraph.org/sites/default/files/kajiya.pdf" rel="nofollow">How to Get Your SIGGRAPH Paper Rejected</a> - Jim Kajiya (Microsoft Research)</li>
<li><a href="/jbhuang0604/awesome-computer-vision/blob/master/www.liyiwei.org/courses/how-siga11/liyiwei.pptx">How to write a SIGGRAPH paper</a> - Li-Yi Wei (The University of Hong Kong)</li>
<li><a href="http://www-hagen.informatik.uni-kl.de/%7Ebertram/talks/getpublished.pdf" rel="nofollow">How to Write a Great Paper</a> - Martin Martin Hering Hering--Bertram (Hochschule Bremen University of Applied Sciences)</li>
<li><a href="http://www-ui.is.s.u-tokyo.ac.jp/%7Etakeo/writings/siggraph.html" rel="nofollow">How to have a paper get into SIGGRAPH?</a> - Takeo Igarashi (The University of Tokyo)</li>
<li><a href="http://www.cs.cmu.edu/%7Epausch/Randy/Randy/raibert.htm" rel="nofollow">Good Writing</a> - Marc H. Raibert (Boston Dynamics, Inc.)</li>
<li><a href="http://web.engr.illinois.edu/%7Edhoiem/presentations/How%20to%20Write%20a%20Computer%20Vison%20Paper.ppt" rel="nofollow">How to Write a Computer Vision Paper</a> - Derek Hoiem (UIUC)</li>
<li><a href="http://www.cs.dartmouth.edu/%7Ewjarosz/writing.html" rel="nofollow">Common mistakes in technical writing</a> - Wojciech Jarosz (Dartmouth College)</li>
</ul>
<h4><a id="user-content-presentation" class="anchor" aria-hidden="true" href="#presentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Presentation</h4>
<ul>
<li><a href="http://people.csail.mit.edu/fredo/TalkAdvice.pdf" rel="nofollow">Giving a Research Talk</a> - Frédo Durand (MIT)</li>
<li><a href="http://www.dgp.toronto.edu/%7Ehertzman/courses/gradSkills/2010/GivingGoodTalks.pdf" rel="nofollow">How to give a good talk</a> - David Fleet (University of Toronto) and Aaron Hertzmann (Adobe Research)</li>
<li><a href="http://colinpurrington.com/tips/poster-design" rel="nofollow">Designing conference posters</a> - Colin Purrington</li>
</ul>
<h4><a id="user-content-research" class="anchor" aria-hidden="true" href="#research"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Research</h4>
<ul>
<li><a href="http://people.csail.mit.edu/billf/www/papers/doresearch.pdf" rel="nofollow">How to do research</a> - William T. Freeman (MIT)</li>
<li><a href="http://www.cs.virginia.edu/%7Erobins/YouAndYourResearch.html" rel="nofollow">You and Your Research</a> - Richard Hamming</li>
<li><a href="http://yima.csl.illinois.edu/psfile/bogus.pdf" rel="nofollow">Warning Signs of Bogus Progress in Research in an Age of Rich Computation and Information</a> - Yi Ma (UIUC)</li>
<li><a href="http://www.quackwatch.com/01QuackeryRelatedTopics/signs.html" rel="nofollow">Seven Warning Signs of Bogus Science</a> - Robert L. Park</li>
<li><a href="https://www.youtube.com/watch?v=v2Qaf8t8I6c" rel="nofollow">Five Principles for Choosing Research Problems in Computer Graphics</a> - Thomas Funkhouser (Cornell University)</li>
<li><a href="http://www.cs.indiana.edu/mit.research.how.to.html" rel="nofollow">How To Do Research In the MIT AI Lab</a> - David Chapman (MIT)</li>
<li><a href="http://www.slideshare.net/antiw/recent-advances-in-computer-vision" rel="nofollow">Recent Advances in Computer Vision</a> - Ming-Hsuan Yang (UC Merced)</li>
<li><a href="http://www.slideshare.net/jbhuang/how-to-come-up-with-new-research-ideas-4005840" rel="nofollow">How to Come Up with Research Ideas in Computer Vision?</a> - Jia-Bin Huang (UIUC)</li>
<li><a href="http://www.slideshare.net/jbhuang/how-to-read-academic-papers" rel="nofollow">How to Read Academic Papers</a> - Jia-Bin Huang (UIUC)</li>
</ul>
<h4><a id="user-content-time-management" class="anchor" aria-hidden="true" href="#time-management"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Time Management</h4>
<ul>
<li><a href="https://www.youtube.com/watch?v=oTugjssqOT0" rel="nofollow">Time Management</a> - Randy Pausch (CMU)</li>
</ul>
<h2><a id="user-content-blogs" class="anchor" aria-hidden="true" href="#blogs"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Blogs</h2>
<ul>
<li><a href="http://www.learnopencv.com/" rel="nofollow">Learn OpenCV</a> - Satya Mallick</li>
<li><a href="http://www.computervisionblog.com/" rel="nofollow">Tombone's Computer Vision Blog</a> - Tomasz Malisiewicz</li>
<li><a href="http://www.visiondummy.com/" rel="nofollow">Computer vision for dummies</a> - Vincent Spruyt</li>
<li><a href="http://karpathy.github.io/" rel="nofollow">Andrej Karpathy blog</a> - Andrej Karpathy</li>
<li><a href="http://aishack.in/" rel="nofollow">AI Shack</a> - Utkarsh Sinha</li>
<li><a href="http://computer-vision-talks.com/" rel="nofollow">Computer Vision Talks</a> - Eugene Khvedchenya</li>
<li><a href="https://github.com/jrobchin/Computer-Vision-Basics-with-Python-Keras-and-OpenCV">Computer Vision Basics with Python Keras and OpenCV</a> - Jason Chin (University of Western Ontario)</li>
</ul>
<h2><a id="user-content-links" class="anchor" aria-hidden="true" href="#links"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Links</h2>
<ul>
<li><a href="http://www.cs.ubc.ca/%7Elowe/vision.html" rel="nofollow">The Computer Vision Industry</a> - David Lowe</li>
<li><a href="http://hci.iwr.uni-heidelberg.de/Links/German_Vision/" rel="nofollow">German Computer Vision Research Groups &amp; Companies</a></li>
<li><a href="https://github.com/ChristosChristofidis/awesome-deep-learning">awesome-deep-learning</a></li>
<li><a href="https://github.com/josephmisiti/awesome-machine-learning">awesome-machine-learning</a></li>
<li><a href="http://www.eecs.berkeley.edu/%7Ejunyanz/cat/cat_papers.html" rel="nofollow">Cat Paper Collection</a></li>
<li><a href="http://www.rsipvision.com/computer-vision-news/" rel="nofollow">Computer Vision News</a></li>
<li></li>
</ul>
<h2><a id="user-content-songs" class="anchor" aria-hidden="true" href="#songs"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Songs</h2>
<ul>
<li><a href="http://danielwedge.com/fmatrix/" rel="nofollow">The Fundamental Matrix Song</a></li>
<li><a href="http://danielwedge.com/ransac/" rel="nofollow">The RANSAC Song</a></li>
<li><a href="https://www.youtube.com/watch?v=DQWI1kvmwRg" rel="nofollow">Machine Learning A Cappella - Overfitting Thriller</a></li>
</ul>
<h2><a id="user-content-licenses" class="anchor" aria-hidden="true" href="#licenses"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Licenses</h2>
<p>License</p>
<p><a href="http://creativecommons.org/publicdomain/zero/1.0/" rel="nofollow"><img src="https://camo.githubusercontent.com/c5160f944848828fa33126d9a697e9abe43ea98f/687474703a2f2f692e6372656174697665636f6d6d6f6e732e6f72672f702f7a65726f2f312e302f38387833312e706e67" alt="CC0" data-canonical-src="http://i.creativecommons.org/p/zero/1.0/88x31.png" style="max-width:100%;"></a></p>
<p>To the extent possible under law, <a href="/jbhuang0604/awesome-computer-vision/blob/master/www.jiabinhuang.com">Jia-Bin Huang</a> has waived all copyright and related or neighboring rights to this work.</p>
</article>
  </div>


  </div>
  <div class="modal-backdrop js-touch-events"></div>
</div>

    </div>
  </div>

  </div>

      
<div class="footer container-lg px-3" role="contentinfo">
  <div class="position-relative d-flex flex-justify-between pt-6 pb-2 mt-6 f6 text-gray border-top border-gray-light ">
    <ul class="list-style-none d-flex flex-wrap ">
      <li class="mr-3">&copy; 2018 <span title="0.40271s from unicorn-758220700-3nlx7">GitHub</span>, Inc.</li>
        <li class="mr-3"><a data-ga-click="Footer, go to terms, text:terms" href="https://github.com/site/terms">Terms</a></li>
        <li class="mr-3"><a data-ga-click="Footer, go to privacy, text:privacy" href="https://github.com/site/privacy">Privacy</a></li>
        <li class="mr-3"><a href="https://help.github.com/articles/github-security/" data-ga-click="Footer, go to security, text:security">Security</a></li>
        <li class="mr-3"><a href="https://status.github.com/" data-ga-click="Footer, go to status, text:status">Status</a></li>
        <li><a data-ga-click="Footer, go to help, text:help" href="https://help.github.com">Help</a></li>
    </ul>

    <a aria-label="Homepage" title="GitHub" class="footer-octicon" href="https://github.com">
      <svg height="24" class="octicon octicon-mark-github" viewBox="0 0 16 16" version="1.1" width="24" aria-hidden="true"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"/></svg>
</a>
   <ul class="list-style-none d-flex flex-wrap ">
        <li class="mr-3"><a data-ga-click="Footer, go to contact, text:contact" href="https://github.com/contact">Contact GitHub</a></li>
      <li class="mr-3"><a href="https://developer.github.com" data-ga-click="Footer, go to api, text:api">API</a></li>
      <li class="mr-3"><a href="https://training.github.com" data-ga-click="Footer, go to training, text:training">Training</a></li>
      <li class="mr-3"><a href="https://shop.github.com" data-ga-click="Footer, go to shop, text:shop">Shop</a></li>
        <li class="mr-3"><a href="https://blog.github.com" data-ga-click="Footer, go to blog, text:blog">Blog</a></li>
        <li><a data-ga-click="Footer, go to about, text:about" href="https://github.com/about">About</a></li>

    </ul>
  </div>
  <div class="d-flex flex-justify-center pb-6">
    <span class="f6 text-gray-light"></span>
  </div>
</div>



  <div id="ajax-error-message" class="ajax-error-message flash flash-error">
    <svg class="octicon octicon-alert" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"/></svg>
    <button type="button" class="flash-close js-ajax-error-dismiss" aria-label="Dismiss error">
      <svg class="octicon octicon-x" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48L7.48 8z"/></svg>
    </button>
    You can’t perform that action at this time.
  </div>


    
    <script crossorigin="anonymous" integrity="sha512-Aff3pZ4kxDZQtwoDgGXK3pyN4iQf3iacjHCHaTq0uvu7OAGAVBmvy1B9BIl72Yr4elhuVbdYlkDdCLOERCA3sw==" type="application/javascript" src="https://assets-cdn.github.com/assets/frameworks-69305c61e4ce67cdef4a70845fc0e959.js"></script>
    
    <script crossorigin="anonymous" async="async" integrity="sha512-lR6qGUwl+E+II1nTIoUOEsiPPSiFXngO9f8qpYgVtj4Qpz3Txge9KdIdqLMLrpdpVLzkTgyB3Un3aexsxttJ8Q==" type="application/javascript" src="https://assets-cdn.github.com/assets/github-bed113001abefcd143ae6f67ad18ff59.js"></script>
    
    
    
    
  <div class="js-stale-session-flash stale-session-flash flash flash-warn flash-banner d-none">
    <svg class="octicon octicon-alert" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"/></svg>
    <span class="signed-in-tab-flash">You signed in with another tab or window. <a href="">Reload</a> to refresh your session.</span>
    <span class="signed-out-tab-flash">You signed out in another tab or window. <a href="">Reload</a> to refresh your session.</span>
  </div>
  <div class="facebox" id="facebox" style="display:none;">
  <div class="facebox-popup">
    <div class="facebox-content" role="dialog" aria-labelledby="facebox-header" aria-describedby="facebox-description">
    </div>
    <button type="button" class="facebox-close js-facebox-close" aria-label="Close modal">
      <svg class="octicon octicon-x" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48L7.48 8z"/></svg>
    </button>
  </div>
</div>

  <div class="Popover js-hovercard-content position-absolute" style="display: none; outline: none;" tabindex="0">
  <div class="Popover-message Popover-message--bottom-left Popover-message--large Box box-shadow-large" style="width:360px;">
  </div>
</div>

<div id="hovercard-aria-description" class="sr-only">
  Press h to open a hovercard with more details.
</div>


  </body>
</html>

